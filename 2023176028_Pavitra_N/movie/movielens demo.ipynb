{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254ab876-2487-43be-984f-4f44d88b6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a63beb-efa4-4711-9fe3-db556a3c6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings.csv')\n",
    "movies = pd.read_csv('movies.csv')\n",
    "users = pd.read_csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d811b21-0e8b-4c91-a8b0-f8447c81e566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp                                   Title  \\\n",
       "0       1     1193       5  978300760  One Flew Over the Cuckoo's Nest (1975)   \n",
       "1       1      661       3  978302109        James and the Giant Peach (1996)   \n",
       "2       1      914       3  978301968                     My Fair Lady (1964)   \n",
       "3       1     3408       4  978300275                  Erin Brockovich (2000)   \n",
       "4       1     2355       5  978824291                    Bug's Life, A (1998)   \n",
       "\n",
       "                         Genres Gender  Age  Occupation Zip-code  \n",
       "0                         Drama      F    1          10    48067  \n",
       "1  Animation|Children's|Musical      F    1          10    48067  \n",
       "2               Musical|Romance      F    1          10    48067  \n",
       "3                         Drama      F    1          10    48067  \n",
       "4   Animation|Children's|Comedy      F    1          10    48067  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(ratings, movies, on='MovieID')\n",
    "data = pd.merge(data, users, on='UserID')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74cdfd9-1e48-40b4-9e29-dc4ee74762ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_to_name = pd.Series(movies.Title.values, index=movies.MovieID).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9083f6a-0619-4a85-b8dd-1a10b73fc312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after filtering: (1000209, 10)\n"
     ]
    }
   ],
   "source": [
    "user_counts = data['UserID'].value_counts()\n",
    "filtered_users = user_counts[user_counts >= 5].index\n",
    "data = data[data['UserID'].isin(filtered_users)]\n",
    "print(f\"Data after filtering: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e646e135-7c0c-4359-90ed-79eb842d1403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after filtering: (999611, 10)\n"
     ]
    }
   ],
   "source": [
    "movie_counts = data['MovieID'].value_counts()\n",
    "filtered_movies = movie_counts[movie_counts >= 5].index\n",
    "data = data[data['MovieID'].isin(filtered_movies)]\n",
    "print(f\"Data after filtering: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d13fea2-dbff-47e5-af7c-60f812e14bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  MovieID           Timestamp\n",
      "0       1     1193 2000-12-31 22:12:40\n",
      "1       1      661 2000-12-31 22:35:09\n",
      "2       1      914 2000-12-31 22:32:48\n",
      "3       1     3408 2000-12-31 22:04:35\n",
      "4       1     2355 2001-01-06 23:38:11\n"
     ]
    }
   ],
   "source": [
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s')\n",
    "print(data[['UserID','MovieID','Timestamp']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fc5be7-ed06-427e-a2d5-2f6f297d8892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "      <th>EncodedUserID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:35:09</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 22:32:48</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 22:04:35</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating           Timestamp  \\\n",
       "0       1     1193       5 2000-12-31 22:12:40   \n",
       "1       1      661       3 2000-12-31 22:35:09   \n",
       "2       1      914       3 2000-12-31 22:32:48   \n",
       "3       1     3408       4 2000-12-31 22:04:35   \n",
       "4       1     2355       5 2001-01-06 23:38:11   \n",
       "\n",
       "                                    Title                        Genres  \\\n",
       "0  One Flew Over the Cuckoo's Nest (1975)                         Drama   \n",
       "1        James and the Giant Peach (1996)  Animation|Children's|Musical   \n",
       "2                     My Fair Lady (1964)               Musical|Romance   \n",
       "3                  Erin Brockovich (2000)                         Drama   \n",
       "4                    Bug's Life, A (1998)   Animation|Children's|Comedy   \n",
       "\n",
       "  Gender  Age  Occupation Zip-code  EncodedUserID  \n",
       "0      F    1          10    48067              1  \n",
       "1      F    1          10    48067              1  \n",
       "2      F    1          10    48067              1  \n",
       "3      F    1          10    48067              1  \n",
       "4      F    1          10    48067              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "data[\"EncodedUserID\"] = user_encoder.fit_transform(data[\"UserID\"]) + 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24707bf1-6fee-4b5d-926f-cef677c7194c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     995\n",
      "1     596\n",
      "2     763\n",
      "3    2926\n",
      "4    1993\n",
      "Name: EncodedMovieID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "movie_encoder = LabelEncoder()\n",
    "data[\"EncodedMovieID\"] = movie_encoder.fit_transform(data[\"MovieID\"]) + 1\n",
    "print (data[\"EncodedMovieID\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee1f134-4250-47c9-924d-f72f12890f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3416\n",
      "3416\n"
     ]
    }
   ],
   "source": [
    "print(data['EncodedMovieID'].nunique())  \n",
    "print(data['EncodedMovieID'].max())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43737989-2766-46b6-a6cd-9ea5ba4ad9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_to_name = pd.Series(movies.Title.values, index=movies.MovieID).to_dict()\n",
    "encoded_movie_id_to_name = {\n",
    "    movie_encoder.transform([k])[0] + 1: v for k, v in movie_id_to_name.items() if k in movie_encoder.classes_\n",
    "}\n",
    "encoded_movie_name_to_id = {v: k for k, v in encoded_movie_id_to_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94496074-5151-4eef-8425-8a3d2a3dce30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EncodedMovieID           Timestamp\n",
      "0            2758 2000-12-31 22:00:19\n",
      "1            1069 2000-12-31 22:00:55\n",
      "2            1445 2000-12-31 22:00:55\n",
      "3             862 2000-12-31 22:00:55\n",
      "4            1979 2000-12-31 22:01:43\n"
     ]
    }
   ],
   "source": [
    "data = data.sort_values([\"EncodedUserID\", \"Timestamp\"]).reset_index(drop=True)\n",
    "print(data[['EncodedMovieID','Timestamp']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a11a1d5-edf2-463a-bb68-1269a1e2ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(sequence, window_size=10):\n",
    "    if len(sequence) < window_size:\n",
    "        sequence = [0] * (window_size - len(sequence)) + sequence        \n",
    "    return [sequence[i:i + window_size] for i in range(len(sequence) - window_size + 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c53b50fa-635a-4919-ae7c-b232b132a7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No EncodedMovieID entry has been assigned the value 0.\n",
      "No EncodedUserID entry has been assigned the value 0.\n"
     ]
    }
   ],
   "source": [
    "if (data['EncodedMovieID'] == 0).any():\n",
    "    print(\"The encoder assigned 0 as a value for some EncodedMovieID entries.\")\n",
    "else:\n",
    "    print(\"No EncodedMovieID entry has been assigned the value 0.\")\n",
    "\n",
    "if (data['EncodedUserID'] == 0).any():\n",
    "    print(\"The encoder assigned 0 as a value for some EncodedUserID entries.\")\n",
    "else:\n",
    "    print(\"No EncodedUserID entry has been assigned the value 0.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "308c2820-c626-47d7-963d-cf4d274b7b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([2758, 1069, 1445, 862, 1979, 1520, 2926, 2412, 1008, 995, 634, 242, 768, 562, 2303, 1631, 1698, 2686, 787, 875, 1632, 1688, 135, 868, 927, 763, 1086, 2405, 2370, 1045, 596, 2514, 497, 2695, 2399, 1960, 869, 998, 551, 2035, 1302, 494, 552, 2298, 649, 546, 1, 1993, 1937, 674, 1315, 1579, 47])\n",
      " list([999, 1011, 1018, 2326, 1092, 2539, 1026, 995, 296, 2617, 2459, 1014, 1615, 1008, 550, 2676, 2981, 1548, 482, 920, 2134, 2622, 105, 1735, 2723, 1046, 2686, 1148, 997, 1627, 1623, 769, 1518, 914, 1632, 2984, 3140, 3218, 1058, 1624, 1486, 2337, 1638, 932, 751, 2967, 3078, 2453, 2868, 2652, 247, 1952, 548, 1052, 2655, 1043, 3183, 1625, 1044, 1885, 3163, 827, 1860, 1914, 1221, 2807, 588, 217, 926, 945, 465, 1045, 3360, 1295, 990, 2033, 1996, 1960, 333, 2689, 1064, 3286, 547, 1698, 2197, 424, 2512, 1353, 447, 148, 357, 2934, 2808, 1192, 21, 326, 1288, 1991, 1676, 1921, 1158, 589, 2064, 1490, 1160, 1308, 2123, 1173, 671, 2481, 2688, 345, 1497, 150, 426, 409, 1341, 2242, 1426, 2809, 644, 1672, 1794, 271, 91, 1423, 402, 1301, 1587])]\n",
      "6040\n"
     ]
    }
   ],
   "source": [
    "user_sequences = data.groupby('EncodedUserID')['EncodedMovieID'].apply(list).values\n",
    "print(user_sequences[:2])\n",
    "print(len(user_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23d7ce60-c3c5-49c0-9082-9af309133f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128306\n"
     ]
    }
   ],
   "source": [
    "user_interaction_counts = [len(seq) for seq in user_sequences]\n",
    "filtered_user_sequences = [\n",
    "    seq for seq, count in zip(user_sequences, user_interaction_counts)\n",
    "    if 10 <= count <= 100  \n",
    "]\n",
    "all_sequences = []\n",
    "for seq in filtered_user_sequences:\n",
    "    all_sequences.extend(generate_sequences(seq))\n",
    "print(len(all_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5994dfa9-2566-4158-b9cc-e1c0b1b687c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2758, 1069, 1445, 862, 1979, 1520, 2926, 2412, 1008, 995], [1069, 1445, 862, 1979, 1520, 2926, 2412, 1008, 995, 634], [1445, 862, 1979, 1520, 2926, 2412, 1008, 995, 634, 242], [862, 1979, 1520, 2926, 2412, 1008, 995, 634, 242, 768], [1979, 1520, 2926, 2412, 1008, 995, 634, 242, 768, 562]]\n"
     ]
    }
   ],
   "source": [
    "print(all_sequences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2163d89f-4873-4197-a87c-3c4549dbddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2758, 1069, 1445,  862, 1979, 1520, 2926, 2412, 1008],\n",
      "        [1069, 1445,  862, 1979, 1520, 2926, 2412, 1008,  995],\n",
      "        [1445,  862, 1979, 1520, 2926, 2412, 1008,  995,  634],\n",
      "        [ 862, 1979, 1520, 2926, 2412, 1008,  995,  634,  242],\n",
      "        [1979, 1520, 2926, 2412, 1008,  995,  634,  242,  768]])\n"
     ]
    }
   ],
   "source": [
    "all_sequences = torch.tensor(all_sequences, dtype=torch.long)\n",
    "inputs = all_sequences[:, :-1]  \n",
    "targets = all_sequences[:, -1]  \n",
    "print(inputs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be632286-4a45-40df-96e3-377e9ba609c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 995,  634,  242,  ..., 1202, 2310,  985])\n"
     ]
    }
   ],
   "source": [
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb3b671a-6c70-4e5c-806b-cd6ca0b31aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([128306, 9]), Targets shape: torch.Size([128306])\n"
     ]
    }
   ],
   "source": [
    "print(f'Inputs shape: {inputs.shape}, Targets shape: {targets.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59cdbc2c-c308-4516-a329-985d01645484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 89814\n",
      "Validation size: 19245\n",
      "Test size: 19247\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)  \n",
    "val_size = int(0.15 * total_size)   \n",
    "test_size = total_size - train_size - val_size  \n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation size: {len(val_loader.dataset)}\")\n",
    "print(f\"Test size: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d966119-b7b0-43df-921c-175ddb6cdee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Inputs: torch.Size([256, 9]), Batch Targets: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for batch_inputs, batch_targets in train_loader:\n",
    "    print(f'Batch Inputs: {batch_inputs.shape}, Batch Targets: {batch_targets.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46048d10-6012-4acd-a9d4-716c4f635695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"movie_mappings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(\n",
    "        {\n",
    "            \"encoded_movie_id_to_name\": encoded_movie_id_to_name,\n",
    "            \"encoded_movie_name_to_id\": encoded_movie_name_to_id,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb1e3d32-4767-4c50-9d07-ad4460bb9ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3417\n"
     ]
    }
   ],
   "source": [
    "num_items = data['EncodedMovieID'].nunique() + 1\n",
    "print(num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "290f9ce9-8e9f-4763-9aec-2a37aeb2a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UET4Rec(\n",
      "  (item_embedding): Embedding(3417, 128, padding_idx=0)\n",
      "  (position_embedding): Embedding(9, 128)\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1)\n",
      "    (3): Dropout(p=0.7, inplace=False)\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1)\n",
      "    (3): Dropout(p=0.7, inplace=False)\n",
      "  )\n",
      "  (encoder3): Sequential(\n",
      "    (0): Conv1d(32, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  )\n",
      "  (transformer): ModuleList(\n",
      "    (0-2): 3 x CustomTransformerEncoderLayer(\n",
      "      (msa): MultiHeadSelfAttention(\n",
      "        (query): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (key): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (value): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (out): Linear(in_features=16, out_features=16, bias=True)\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "      )\n",
      "      (ffn): PointWiseFeedForward(\n",
      "        (linear1): Linear(in_features=16, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.7, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=16, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.7, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (decoder1): Sequential(\n",
      "    (0): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1)\n",
      "    (3): Dropout(p=0.7, inplace=False)\n",
      "  )\n",
      "  (decoder2): Sequential(\n",
      "    (0): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.1)\n",
      "    (3): Dropout(p=0.7, inplace=False)\n",
      "  )\n",
      "  (decoder3): Sequential(\n",
      "    (0): Conv1d(64, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  )\n",
      "  (ma): ModelAugmentation(\n",
      "    (ffn): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.7, inplace=False)\n",
      "      (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=3417, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, dropout=0.1):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embedding_dim // num_heads\n",
    "\n",
    "        assert embedding_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads\"\n",
    "\n",
    "        self.query = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.key = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.value = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "        self.out = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, E = x.size()  \n",
    "\n",
    "        Q = self.query(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = self.key(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = self.value(x).view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        output = torch.matmul(attn, V)\n",
    "        output = output.transpose(1, 2).contiguous().view(B, N, E)\n",
    "\n",
    "        return self.out(output)\n",
    "\n",
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, embedding_dim, ff_dim, dropout=0.1):\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(embedding_dim, ff_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(ff_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear1(x)))\n",
    "        return self.linear2(x)\n",
    "\n",
    "class CustomTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(CustomTransformerEncoderLayer, self).__init__()\n",
    "        self.msa = MultiHeadSelfAttention(embedding_dim, num_heads, dropout)\n",
    "        self.ffn = PointWiseFeedForward(embedding_dim, ff_dim, dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.dropout(self.msa(self.norm1(x)))\n",
    "        x = x + self.dropout(self.ffn(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "class ModelAugmentation(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout=0.1):\n",
    "        super(ModelAugmentation, self).__init__()\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(self.ffn(x) + x)\n",
    "\n",
    "class UET4Rec(nn.Module):\n",
    "    def __init__(self, num_items, embedding_dim=128, nhead=8, max_len=9, dropout=0.7, ff_dim=256):\n",
    "        super(UET4Rec, self).__init__()\n",
    "\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_dim)\n",
    "\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim, embedding_dim // 2, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(embedding_dim // 2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim // 2, embedding_dim // 4, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(embedding_dim // 4),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim // 4, embedding_dim // 8, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.ModuleList([\n",
    "            CustomTransformerEncoderLayer(embedding_dim // 8, nhead, ff_dim, dropout) for _ in range(3)\n",
    "        ])\n",
    "\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim // 8, embedding_dim // 4, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(embedding_dim // 4),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim // 4, embedding_dim // 2, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(embedding_dim // 2),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim // 2, embedding_dim, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        self.ma = ModelAugmentation(embedding_dim, dropout)\n",
    "\n",
    "        self.fc = nn.Linear(embedding_dim, num_items)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        positions = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(x.device)\n",
    "        x = self.item_embedding(x) + self.position_embedding(positions)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(enc1)\n",
    "        enc3 = self.encoder3(enc2)\n",
    "\n",
    "        x = enc3.permute(0, 2, 1)  \n",
    "        for layer in self.transformer:\n",
    "            x = layer(x)\n",
    "        x = x.permute(0, 2, 1)  \n",
    "\n",
    "        dec1 = self.decoder1(x + enc3)  \n",
    "        dec2 = self.decoder2(dec1 + enc2)  \n",
    "        dec3 = self.decoder3(dec2 + enc1)  \n",
    "\n",
    "        x = dec3[:, :, -1]  \n",
    "        x = self.ma(x)  \n",
    "        out = self.fc(x)  \n",
    "\n",
    "        return out\n",
    "embedding_dim = 128\n",
    "nhead = 8\n",
    "ff_dim = 256\n",
    "dropout = 0.7\n",
    "max_len = 9\n",
    "\n",
    "model = UET4Rec(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    nhead=nhead,\n",
    "    max_len=max_len,\n",
    "    dropout=dropout,\n",
    "    ff_dim=ff_dim\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6b50493-0527-4a17-a2a1-ce8c28fac922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/250]: 100%|█████████████████████████████████████████████| 351/351 [00:26<00:00, 13.43batch/s, Batch Loss=7.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Training Loss: 7.2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/250]: 100%|█████████████████████████████████████████████| 351/351 [00:16<00:00, 20.88batch/s, Batch Loss=7.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/250], Training Loss: 7.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/250]: 100%|█████████████████████████████████████████████| 351/351 [00:16<00:00, 21.08batch/s, Batch Loss=6.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/250], Training Loss: 6.8644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/250]: 100%|█████████████████████████████████████████████| 351/351 [00:17<00:00, 20.62batch/s, Batch Loss=6.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/250], Training Loss: 6.3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/250]: 100%|█████████████████████████████████████████████| 351/351 [00:16<00:00, 21.07batch/s, Batch Loss=6.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/250], Training Loss: 6.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/250]: 100%|██████████████████████████████████████████████| 351/351 [00:14<00:00, 23.75batch/s, Batch Loss=6.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/250], Training Loss: 5.9441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/250]: 100%|█████████████████████████████████████████████| 351/351 [00:14<00:00, 23.43batch/s, Batch Loss=5.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/250], Training Loss: 5.8318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/250]: 100%|█████████████████████████████████████████████| 351/351 [00:15<00:00, 23.00batch/s, Batch Loss=5.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/250], Training Loss: 5.7431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/250]: 100%|█████████████████████████████████████████████| 351/351 [00:14<00:00, 24.37batch/s, Batch Loss=5.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/250], Training Loss: 5.6695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.93batch/s, Batch Loss=5.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/250], Training Loss: 5.6091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/250]: 100%|█████████████████████████████████████████████| 351/351 [00:15<00:00, 22.86batch/s, Batch Loss=5.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/250], Training Loss: 5.5536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.45batch/s, Batch Loss=5.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/250], Training Loss: 5.5115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.46batch/s, Batch Loss=5.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/250], Training Loss: 5.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.24batch/s, Batch Loss=5.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/250], Training Loss: 5.4291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.04batch/s, Batch Loss=5.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/250], Training Loss: 5.3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.85batch/s, Batch Loss=5.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/250], Training Loss: 5.3587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/250]: 100%|████████████████████████████████████████████| 351/351 [00:16<00:00, 21.81batch/s, Batch Loss=5.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/250], Training Loss: 5.3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/250]: 100%|████████████████████████████████████████████| 351/351 [00:16<00:00, 21.59batch/s, Batch Loss=5.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/250], Training Loss: 5.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.26batch/s, Batch Loss=5.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/250], Training Loss: 5.2868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.18batch/s, Batch Loss=5.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/250], Training Loss: 5.2619\n",
      "Model saved after 20 epochs at 'uet4rec_model_epoch_20.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/250]: 100%|█████████████████████████████████████████████| 351/351 [00:14<00:00, 24.60batch/s, Batch Loss=5.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/250], Training Loss: 5.2336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.96batch/s, Batch Loss=5.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/250], Training Loss: 5.2202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.70batch/s, Batch Loss=5.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/250], Training Loss: 5.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 23.72batch/s, Batch Loss=5.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/250], Training Loss: 5.1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.79batch/s, Batch Loss=5.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/250], Training Loss: 5.1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.10batch/s, Batch Loss=5.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/250], Training Loss: 5.1395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/250]: 100%|█████████████████████████████████████████████| 351/351 [00:14<00:00, 24.62batch/s, Batch Loss=5.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/250], Training Loss: 5.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.83batch/s, Batch Loss=5.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/250], Training Loss: 5.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.41batch/s, Batch Loss=5.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/250], Training Loss: 5.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.98batch/s, Batch Loss=4.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/250], Training Loss: 5.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.10batch/s, Batch Loss=5.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/250], Training Loss: 5.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.91batch/s, Batch Loss=5.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/250], Training Loss: 5.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 23.36batch/s, Batch Loss=4.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/250], Training Loss: 5.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.35batch/s, Batch Loss=5.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/250], Training Loss: 5.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 23.52batch/s, Batch Loss=5.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/250], Training Loss: 5.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.47batch/s, Batch Loss=5.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/250], Training Loss: 4.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.25batch/s, Batch Loss=5.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/250], Training Loss: 4.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.48batch/s, Batch Loss=4.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/250], Training Loss: 4.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.59batch/s, Batch Loss=4.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/250], Training Loss: 4.9507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.38batch/s, Batch Loss=5.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/250], Training Loss: 4.9418\n",
      "Model saved after 40 epochs at 'uet4rec_model_epoch_40.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.89batch/s, Batch Loss=4.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/250], Training Loss: 4.9229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.25batch/s, Batch Loss=5.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/250], Training Loss: 4.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.60batch/s, Batch Loss=5.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/250], Training Loss: 4.8969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.46batch/s, Batch Loss=4.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/250], Training Loss: 4.8872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/250]: 100%|███████████████████████████████████████████████| 351/351 [00:14<00:00, 24.24batch/s, Batch Loss=5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/250], Training Loss: 4.8823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.22batch/s, Batch Loss=4.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/250], Training Loss: 4.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 25.07batch/s, Batch Loss=5.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/250], Training Loss: 4.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.72batch/s, Batch Loss=5.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/250], Training Loss: 4.8461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.89batch/s, Batch Loss=4.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/250], Training Loss: 4.8374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.48batch/s, Batch Loss=4.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/250], Training Loss: 4.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.85batch/s, Batch Loss=5.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/250], Training Loss: 4.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.87batch/s, Batch Loss=4.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/250], Training Loss: 4.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.80batch/s, Batch Loss=4.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/250], Training Loss: 4.8006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 25.06batch/s, Batch Loss=4.96]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/250], Training Loss: 4.7873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.85batch/s, Batch Loss=4.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/250], Training Loss: 4.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.37batch/s, Batch Loss=4.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/250], Training Loss: 4.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.96batch/s, Batch Loss=4.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/250], Training Loss: 4.7646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.41batch/s, Batch Loss=4.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/250], Training Loss: 4.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.47batch/s, Batch Loss=4.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/250], Training Loss: 4.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60/250]: 100%|█████████████████████████████████████████████| 351/351 [00:16<00:00, 21.27batch/s, Batch Loss=4.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/250], Training Loss: 4.7324\n",
      "Model saved after 60 epochs at 'uet4rec_model_epoch_60.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [61/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.02batch/s, Batch Loss=5.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/250], Training Loss: 4.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [62/250]: 100%|████████████████████████████████████████████| 351/351 [00:17<00:00, 19.54batch/s, Batch Loss=4.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/250], Training Loss: 4.7187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [63/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 23.36batch/s, Batch Loss=4.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/250], Training Loss: 4.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [64/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.72batch/s, Batch Loss=4.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/250], Training Loss: 4.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [65/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.10batch/s, Batch Loss=4.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/250], Training Loss: 4.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [66/250]: 100%|████████████████████████████████████████████| 351/351 [00:16<00:00, 21.27batch/s, Batch Loss=4.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/250], Training Loss: 4.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [67/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.01batch/s, Batch Loss=4.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/250], Training Loss: 4.6852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [68/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 23.04batch/s, Batch Loss=4.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/250], Training Loss: 4.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [69/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.59batch/s, Batch Loss=4.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/250], Training Loss: 4.6670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [70/250]: 100%|████████████████████████████████████████████| 351/351 [00:17<00:00, 20.45batch/s, Batch Loss=4.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/250], Training Loss: 4.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [71/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.40batch/s, Batch Loss=4.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/250], Training Loss: 4.6483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [72/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.70batch/s, Batch Loss=4.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/250], Training Loss: 4.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [73/250]: 100%|████████████████████████████████████████████| 351/351 [00:16<00:00, 20.67batch/s, Batch Loss=4.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/250], Training Loss: 4.6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [74/250]: 100%|█████████████████████████████████████████████| 351/351 [00:17<00:00, 19.87batch/s, Batch Loss=4.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/250], Training Loss: 4.6252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [75/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.48batch/s, Batch Loss=4.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/250], Training Loss: 4.6255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [76/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.68batch/s, Batch Loss=4.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/250], Training Loss: 4.6106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [77/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.18batch/s, Batch Loss=4.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/250], Training Loss: 4.6060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [78/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.34batch/s, Batch Loss=4.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/250], Training Loss: 4.6022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [79/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 27.26batch/s, Batch Loss=4.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/250], Training Loss: 4.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [80/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 27.67batch/s, Batch Loss=4.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/250], Training Loss: 4.5871\n",
      "Model saved after 80 epochs at 'uet4rec_model_epoch_80.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [81/250]: 100%|█████████████████████████████████████████████| 351/351 [00:13<00:00, 25.93batch/s, Batch Loss=4.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/250], Training Loss: 4.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [82/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 28.62batch/s, Batch Loss=4.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/250], Training Loss: 4.5784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [83/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 27.44batch/s, Batch Loss=4.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/250], Training Loss: 4.5696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [84/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 29.66batch/s, Batch Loss=4.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/250], Training Loss: 4.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [85/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 28.69batch/s, Batch Loss=4.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/250], Training Loss: 4.5611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [86/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 30.47batch/s, Batch Loss=4.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/250], Training Loss: 4.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [87/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 27.67batch/s, Batch Loss=4.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/250], Training Loss: 4.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [88/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 28.69batch/s, Batch Loss=4.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/250], Training Loss: 4.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [89/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 28.66batch/s, Batch Loss=4.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/250], Training Loss: 4.5361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [90/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 30.34batch/s, Batch Loss=4.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/250], Training Loss: 4.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [91/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 27.73batch/s, Batch Loss=4.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/250], Training Loss: 4.5191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [92/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 30.32batch/s, Batch Loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/250], Training Loss: 4.5162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [93/250]: 100%|█████████████████████████████████████████████| 351/351 [00:12<00:00, 27.60batch/s, Batch Loss=4.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/250], Training Loss: 4.5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [94/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 28.85batch/s, Batch Loss=4.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/250], Training Loss: 4.5034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [95/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 30.16batch/s, Batch Loss=4.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/250], Training Loss: 4.4895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [96/250]: 100%|████████████████████████████████████████████| 351/351 [00:12<00:00, 27.02batch/s, Batch Loss=4.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/250], Training Loss: 4.4860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [97/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 23.29batch/s, Batch Loss=4.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/250], Training Loss: 4.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [98/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.75batch/s, Batch Loss=4.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/250], Training Loss: 4.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [99/250]: 100%|████████████████████████████████████████████| 351/351 [00:15<00:00, 22.81batch/s, Batch Loss=4.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/250], Training Loss: 4.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [100/250]: 100%|███████████████████████████████████████████| 351/351 [00:15<00:00, 22.39batch/s, Batch Loss=4.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/250], Training Loss: 4.4748\n",
      "Model saved after 100 epochs at 'uet4rec_model_epoch_100.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [101/250]: 100%|███████████████████████████████████████████| 351/351 [00:14<00:00, 23.51batch/s, Batch Loss=4.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [101/250], Training Loss: 4.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [102/250]: 100%|███████████████████████████████████████████| 351/351 [00:14<00:00, 23.44batch/s, Batch Loss=4.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [102/250], Training Loss: 4.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [103/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 26.41batch/s, Batch Loss=4.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/250], Training Loss: 4.4561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [104/250]: 100%|███████████████████████████████████████████| 351/351 [00:16<00:00, 21.62batch/s, Batch Loss=4.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [104/250], Training Loss: 4.4534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [105/250]: 100%|███████████████████████████████████████████| 351/351 [00:16<00:00, 21.17batch/s, Batch Loss=4.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [105/250], Training Loss: 4.4432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [106/250]: 100%|███████████████████████████████████████████| 351/351 [00:18<00:00, 19.25batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [106/250], Training Loss: 4.4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [107/250]: 100%|███████████████████████████████████████████| 351/351 [00:18<00:00, 18.95batch/s, Batch Loss=4.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/250], Training Loss: 4.4387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [108/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 26.00batch/s, Batch Loss=4.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/250], Training Loss: 4.4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [109/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 27.85batch/s, Batch Loss=4.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [109/250], Training Loss: 4.4218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [110/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.98batch/s, Batch Loss=4.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/250], Training Loss: 4.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [111/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 27.71batch/s, Batch Loss=4.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/250], Training Loss: 4.4187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [112/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 28.09batch/s, Batch Loss=4.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/250], Training Loss: 4.4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [113/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 29.33batch/s, Batch Loss=4.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/250], Training Loss: 4.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [114/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 26.12batch/s, Batch Loss=4.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [114/250], Training Loss: 4.4010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [115/250]: 100%|████████████████████████████████████████████| 351/351 [00:14<00:00, 24.49batch/s, Batch Loss=4.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [115/250], Training Loss: 4.3971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [116/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 25.81batch/s, Batch Loss=4.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [116/250], Training Loss: 4.3917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [117/250]: 100%|███████████████████████████████████████████| 351/351 [00:14<00:00, 23.96batch/s, Batch Loss=4.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/250], Training Loss: 4.3904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [118/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 30.63batch/s, Batch Loss=4.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [118/250], Training Loss: 4.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [119/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.22batch/s, Batch Loss=4.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/250], Training Loss: 4.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [120/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 29.83batch/s, Batch Loss=4.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [120/250], Training Loss: 4.3762\n",
      "Model saved after 120 epochs at 'uet4rec_model_epoch_120.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [121/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 28.46batch/s, Batch Loss=4.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/250], Training Loss: 4.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [122/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.11batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [122/250], Training Loss: 4.3622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [123/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.44batch/s, Batch Loss=4.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/250], Training Loss: 4.3659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [124/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.63batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/250], Training Loss: 4.3508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [125/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.10batch/s, Batch Loss=4.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [125/250], Training Loss: 4.3476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [126/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 29.83batch/s, Batch Loss=4.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/250], Training Loss: 4.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [127/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.52batch/s, Batch Loss=4.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/250], Training Loss: 4.3384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [128/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.06batch/s, Batch Loss=4.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [128/250], Training Loss: 4.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [129/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 30.98batch/s, Batch Loss=4.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [129/250], Training Loss: 4.3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [130/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.24batch/s, Batch Loss=4.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/250], Training Loss: 4.3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [131/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.94batch/s, Batch Loss=4.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/250], Training Loss: 4.3229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [132/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.34batch/s, Batch Loss=4.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [132/250], Training Loss: 4.3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [133/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.38batch/s, Batch Loss=4.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [133/250], Training Loss: 4.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [134/250]: 100%|████████████████████████████████████████████| 351/351 [00:11<00:00, 31.89batch/s, Batch Loss=4.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [134/250], Training Loss: 4.3116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [135/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.71batch/s, Batch Loss=4.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/250], Training Loss: 4.3053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [136/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.36batch/s, Batch Loss=4.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [136/250], Training Loss: 4.3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [137/250]: 100%|███████████████████████████████████████████| 351/351 [00:09<00:00, 36.71batch/s, Batch Loss=4.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [137/250], Training Loss: 4.3071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [138/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.87batch/s, Batch Loss=4.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/250], Training Loss: 4.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [139/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.02batch/s, Batch Loss=4.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/250], Training Loss: 4.2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [140/250]: 100%|███████████████████████████████████████████| 351/351 [00:09<00:00, 36.23batch/s, Batch Loss=4.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [140/250], Training Loss: 4.2958\n",
      "Model saved after 140 epochs at 'uet4rec_model_epoch_140.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [141/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.58batch/s, Batch Loss=4.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [141/250], Training Loss: 4.2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [142/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.90batch/s, Batch Loss=4.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [142/250], Training Loss: 4.2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [143/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.79batch/s, Batch Loss=4.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [143/250], Training Loss: 4.2795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [144/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.13batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/250], Training Loss: 4.2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [145/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.59batch/s, Batch Loss=4.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/250], Training Loss: 4.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [146/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.33batch/s, Batch Loss=4.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/250], Training Loss: 4.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [147/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.67batch/s, Batch Loss=4.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [147/250], Training Loss: 4.2668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [148/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.74batch/s, Batch Loss=4.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/250], Training Loss: 4.2608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [149/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.14batch/s, Batch Loss=4.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [149/250], Training Loss: 4.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [150/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 34.54batch/s, Batch Loss=4.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [150/250], Training Loss: 4.2524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [151/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 33.72batch/s, Batch Loss=4.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [151/250], Training Loss: 4.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [152/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.20batch/s, Batch Loss=4.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/250], Training Loss: 4.2439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [153/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.34batch/s, Batch Loss=4.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/250], Training Loss: 4.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [154/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.18batch/s, Batch Loss=4.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [154/250], Training Loss: 4.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [155/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.78batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [155/250], Training Loss: 4.2386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [156/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.07batch/s, Batch Loss=4.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [156/250], Training Loss: 4.2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [157/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.78batch/s, Batch Loss=4.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/250], Training Loss: 4.2314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [158/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.33batch/s, Batch Loss=4.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/250], Training Loss: 4.2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [159/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 33.05batch/s, Batch Loss=4.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/250], Training Loss: 4.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [160/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.81batch/s, Batch Loss=4.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [160/250], Training Loss: 4.2184\n",
      "Model saved after 160 epochs at 'uet4rec_model_epoch_160.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [161/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.33batch/s, Batch Loss=4.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [161/250], Training Loss: 4.2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [162/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.62batch/s, Batch Loss=4.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/250], Training Loss: 4.2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [163/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.85batch/s, Batch Loss=4.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [163/250], Training Loss: 4.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [164/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.76batch/s, Batch Loss=4.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [164/250], Training Loss: 4.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [165/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 28.56batch/s, Batch Loss=4.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/250], Training Loss: 4.2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [166/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.44batch/s, Batch Loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166/250], Training Loss: 4.2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [167/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 27.79batch/s, Batch Loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/250], Training Loss: 4.2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [168/250]: 100%|████████████████████████████████████████████| 351/351 [00:13<00:00, 25.60batch/s, Batch Loss=4.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [168/250], Training Loss: 4.1948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [169/250]: 100%|███████████████████████████████████████████| 351/351 [00:14<00:00, 24.44batch/s, Batch Loss=4.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [169/250], Training Loss: 4.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [170/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 28.14batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [170/250], Training Loss: 4.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [171/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.00batch/s, Batch Loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/250], Training Loss: 4.1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [172/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 26.86batch/s, Batch Loss=4.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [172/250], Training Loss: 4.1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [173/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 26.88batch/s, Batch Loss=4.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [173/250], Training Loss: 4.1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [174/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 29.26batch/s, Batch Loss=4.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [174/250], Training Loss: 4.1848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [175/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 27.98batch/s, Batch Loss=4.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/250], Training Loss: 4.1743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [176/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 25.95batch/s, Batch Loss=4.58]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/250], Training Loss: 4.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [177/250]: 100%|███████████████████████████████████████████| 351/351 [00:12<00:00, 27.25batch/s, Batch Loss=4.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [177/250], Training Loss: 4.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [178/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.61batch/s, Batch Loss=4.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [178/250], Training Loss: 4.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [179/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.42batch/s, Batch Loss=4.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/250], Training Loss: 4.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [180/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.03batch/s, Batch Loss=4.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/250], Training Loss: 4.1629\n",
      "Model saved after 180 epochs at 'uet4rec_model_epoch_180.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [181/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.32batch/s, Batch Loss=4.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [181/250], Training Loss: 4.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [182/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 33.02batch/s, Batch Loss=4.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [182/250], Training Loss: 4.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [183/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.17batch/s, Batch Loss=4.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [183/250], Training Loss: 4.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [184/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.28batch/s, Batch Loss=4.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/250], Training Loss: 4.1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [185/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.58batch/s, Batch Loss=4.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/250], Training Loss: 4.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [186/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.44batch/s, Batch Loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [186/250], Training Loss: 4.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [187/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.04batch/s, Batch Loss=4.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [187/250], Training Loss: 4.1426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [188/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 33.51batch/s, Batch Loss=4.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [188/250], Training Loss: 4.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [189/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.86batch/s, Batch Loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/250], Training Loss: 4.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [190/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.57batch/s, Batch Loss=4.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/250], Training Loss: 4.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [191/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.64batch/s, Batch Loss=4.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/250], Training Loss: 4.1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [192/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.14batch/s, Batch Loss=4.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/250], Training Loss: 4.1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [193/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.59batch/s, Batch Loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/250], Training Loss: 4.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [194/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 25.95batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/250], Training Loss: 4.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [195/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.18batch/s, Batch Loss=4.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [195/250], Training Loss: 4.1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [196/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.70batch/s, Batch Loss=4.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/250], Training Loss: 4.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [197/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.58batch/s, Batch Loss=4.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [197/250], Training Loss: 4.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [198/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.30batch/s, Batch Loss=4.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [198/250], Training Loss: 4.1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [199/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.67batch/s, Batch Loss=4.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [199/250], Training Loss: 4.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [200/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.47batch/s, Batch Loss=4.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/250], Training Loss: 4.1057\n",
      "Model saved after 200 epochs at 'uet4rec_model_epoch_200.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [201/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.59batch/s, Batch Loss=4.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [201/250], Training Loss: 4.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [202/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.14batch/s, Batch Loss=3.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [202/250], Training Loss: 4.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [203/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.48batch/s, Batch Loss=4.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [203/250], Training Loss: 4.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [204/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.58batch/s, Batch Loss=4.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [204/250], Training Loss: 4.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [205/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.46batch/s, Batch Loss=4.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [205/250], Training Loss: 4.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [206/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 25.60batch/s, Batch Loss=4.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [206/250], Training Loss: 4.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [207/250]: 100%|███████████████████████████████████████████| 351/351 [00:14<00:00, 24.78batch/s, Batch Loss=4.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [207/250], Training Loss: 4.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [208/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.38batch/s, Batch Loss=4.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [208/250], Training Loss: 4.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [209/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.39batch/s, Batch Loss=4.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [209/250], Training Loss: 4.0826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [210/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.82batch/s, Batch Loss=4.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [210/250], Training Loss: 4.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [211/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.55batch/s, Batch Loss=4.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [211/250], Training Loss: 4.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [212/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.09batch/s, Batch Loss=3.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [212/250], Training Loss: 4.0682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [213/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 32.87batch/s, Batch Loss=4.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [213/250], Training Loss: 4.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [214/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.72batch/s, Batch Loss=4.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [214/250], Training Loss: 4.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [215/250]: 100%|███████████████████████████████████████████| 351/351 [00:15<00:00, 23.38batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [215/250], Training Loss: 4.0657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [216/250]: 100%|███████████████████████████████████████████| 351/351 [00:17<00:00, 20.48batch/s, Batch Loss=4.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [216/250], Training Loss: 4.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [217/250]: 100%|███████████████████████████████████████████| 351/351 [00:16<00:00, 20.79batch/s, Batch Loss=3.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [217/250], Training Loss: 4.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [218/250]: 100%|███████████████████████████████████████████| 351/351 [00:16<00:00, 21.03batch/s, Batch Loss=4.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [218/250], Training Loss: 4.0579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [219/250]: 100%|███████████████████████████████████████████| 351/351 [00:13<00:00, 25.25batch/s, Batch Loss=4.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [219/250], Training Loss: 4.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [220/250]: 100%|██████████████████████████████████████████████| 351/351 [00:11<00:00, 29.37batch/s, Batch Loss=4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [220/250], Training Loss: 4.0530\n",
      "Model saved after 220 epochs at 'uet4rec_model_epoch_220.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [221/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.19batch/s, Batch Loss=4.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [221/250], Training Loss: 4.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [222/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.49batch/s, Batch Loss=4.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [222/250], Training Loss: 4.0441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [223/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.24batch/s, Batch Loss=4.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [223/250], Training Loss: 4.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [224/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 30.54batch/s, Batch Loss=4.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [224/250], Training Loss: 4.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [225/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.07batch/s, Batch Loss=4.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [225/250], Training Loss: 4.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [226/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 29.41batch/s, Batch Loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [226/250], Training Loss: 4.0449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [227/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.81batch/s, Batch Loss=4.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [227/250], Training Loss: 4.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [228/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.78batch/s, Batch Loss=4.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [228/250], Training Loss: 4.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [229/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.76batch/s, Batch Loss=3.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [229/250], Training Loss: 4.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [230/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.58batch/s, Batch Loss=3.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [230/250], Training Loss: 4.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [231/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.48batch/s, Batch Loss=4.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [231/250], Training Loss: 4.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [232/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.39batch/s, Batch Loss=4.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [232/250], Training Loss: 4.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [233/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.57batch/s, Batch Loss=4.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [233/250], Training Loss: 4.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [234/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.64batch/s, Batch Loss=4.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [234/250], Training Loss: 4.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [235/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.68batch/s, Batch Loss=4.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [235/250], Training Loss: 4.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [236/250]: 100%|██████████████████████████████████████████████| 351/351 [00:10<00:00, 34.65batch/s, Batch Loss=4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [236/250], Training Loss: 4.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [237/250]: 100%|███████████████████████████████████████████| 351/351 [00:11<00:00, 31.27batch/s, Batch Loss=4.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [237/250], Training Loss: 4.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [238/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.84batch/s, Batch Loss=4.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [238/250], Training Loss: 4.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [239/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.64batch/s, Batch Loss=3.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [239/250], Training Loss: 4.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [240/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.08batch/s, Batch Loss=4.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [240/250], Training Loss: 4.0100\n",
      "Model saved after 240 epochs at 'uet4rec_model_epoch_240.pth'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [241/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.91batch/s, Batch Loss=3.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [241/250], Training Loss: 4.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [242/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.09batch/s, Batch Loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [242/250], Training Loss: 4.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [243/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 34.52batch/s, Batch Loss=3.94]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [243/250], Training Loss: 4.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [244/250]: 100%|██████████████████████████████████████████████| 351/351 [00:10<00:00, 33.13batch/s, Batch Loss=4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [244/250], Training Loss: 3.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [245/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.68batch/s, Batch Loss=4.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [245/250], Training Loss: 4.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [246/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 32.61batch/s, Batch Loss=4.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [246/250], Training Loss: 3.9970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [247/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 34.61batch/s, Batch Loss=4.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [247/250], Training Loss: 3.9926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [248/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 33.38batch/s, Batch Loss=3.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [248/250], Training Loss: 3.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [249/250]: 100%|████████████████████████████████████████████| 351/351 [00:10<00:00, 33.52batch/s, Batch Loss=3.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [249/250], Training Loss: 3.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [250/250]: 100%|███████████████████████████████████████████| 351/351 [00:10<00:00, 33.16batch/s, Batch Loss=3.97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [250/250], Training Loss: 3.9821\n",
      "Final model saved as 'uet4rec_model_final.pth'.\n",
      "Training Completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 250\n",
    "save_interval = 20  \n",
    "print(\"Starting Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    total_loss = 0.0\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", unit=\"batch\") as progress_bar:\n",
    "        for batch_inputs, batch_targets in progress_bar:\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            progress_bar.set_postfix({\"Batch Loss\": loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % save_interval == 0:\n",
    "        model_save_path = f\"uet4rec_model_epoch_{epoch+1}.pth\"\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Model saved after {epoch+1} epochs at '{model_save_path}'.\")\n",
    "\n",
    "final_model_path = \"uet4rec_model_final.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Final model saved as '{final_model_path}'.\")\n",
    "\n",
    "print(\"Training Completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d4bb5a6-8a5f-4b90-ab44-cead3bb0f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "model = UET4Rec(\n",
    "    num_items=num_items,\n",
    "    embedding_dim=embedding_dim,\n",
    "    nhead=nhead,\n",
    "    max_len=max_len,\n",
    "    dropout=dropout,\n",
    "    ff_dim=ff_dim\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92b3a220-ac14-4a4d-94a2-95f2259ad4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npavi\\AppData\\Local\\Temp\\ipykernel_5896\\2742463541.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"uet4rec_model_final.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"uet4rec_model_final.pth\", map_location=device)) \n",
    "model.to(device)\n",
    "model.eval() \n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5c239f2-772c-45eb-9f5d-d6b3aa6a8a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating HR & NDCG for multiple k: 100%|█████████████████████████████████████████████| 76/76 [00:09<00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics Summary:\n",
      "HR@5: 0.4739\n",
      "NDCG@5: 0.3774\n",
      "HR@10: 0.5774\n",
      "NDCG@10: 0.4109\n",
      "HR@20: 0.6850\n",
      "NDCG@20: 0.4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def evaluate_hit_ndcg_multi_k(model, test_loader, ks=[5, 10, 20]):\n",
    "    model.eval()\n",
    "    total_hr = {k: 0 for k in ks}\n",
    "    total_ndcg = {k: 0 for k in ks}\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_targets in tqdm(test_loader, desc=\"Evaluating HR & NDCG for multiple k\"):\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "            outputs = model(batch_inputs)  \n",
    "            _, top_k_indices = torch.topk(outputs, k=max(ks), dim=1) \n",
    "\n",
    "            for i in range(batch_targets.size(0)):\n",
    "                target = batch_targets[i].item()\n",
    "                predictions = top_k_indices[i].cpu().numpy()\n",
    "\n",
    "                for k in ks:\n",
    "                    top_k_preds = predictions[:k]\n",
    "\n",
    "                    if target in top_k_preds:\n",
    "                        total_hr[k] += 1\n",
    "\n",
    "                    if target in top_k_preds:\n",
    "                        rank = np.where(top_k_preds == target)[0][0] + 1\n",
    "                        total_ndcg[k] += 1 / np.log2(rank + 1)\n",
    "\n",
    "            total_samples += batch_targets.size(0)\n",
    "\n",
    "    hr = {k: total_hr[k] / total_samples for k in ks}\n",
    "    ndcg = {k: total_ndcg[k] / total_samples for k in ks}\n",
    "\n",
    "    return hr, ndcg\n",
    "\n",
    "k_values = [5, 10, 20]\n",
    "hr, ndcg = evaluate_hit_ndcg_multi_k(model, test_loader, ks=k_values)\n",
    "\n",
    "print(\"\\nMetrics Summary:\")\n",
    "for k in k_values:\n",
    "    print(f\"HR@{k}: {hr[k]:.4f}\")\n",
    "    print(f\"NDCG@{k}: {ndcg[k]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d2c6b0c-e3f3-4a02-ba5d-6337d434e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42e4c95e-76aa-4c9b-a09d-45f5179d4f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npavi\\AppData\\Local\\Temp\\ipykernel_5896\\146851217.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"uet4rec_model_final.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Movie Recommendation System!\n",
      "Type a movie name to get recommendations, or type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a movie name:  Toy Story (1995)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for 'Toy Story (1995)':\n",
      "1. Toy Story 2 (1999)\n",
      "2. Groundhog Day (1993)\n",
      "3. Steel Magnolias (1989)\n",
      "4. There's Something About Mary (1998)\n",
      "5. Full Monty, The (1997)\n",
      "6. Bull Durham (1988)\n",
      "7. American Beauty (1999)\n",
      "8. Scary Movie (2000)\n",
      "9. Young Frankenstein (1974)\n",
      "10. Wizard of Oz, The (1939)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a movie name:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using the Movie Recommendation System. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def recommend_movies(model, movie_name, encoded_movie_name_to_id, encoded_movie_id_to_name, top_k=10):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    if movie_name not in encoded_movie_name_to_id:\n",
    "        return f\"Movie '{movie_name}' not found in the dataset. Please try another movie.\"\n",
    "\n",
    "    input_movie_id = encoded_movie_name_to_id[movie_name]\n",
    "\n",
    "    input_sequence = [0] * (max_len - 1) + [input_movie_id]  # Pad with zeros\n",
    "    input_tensor = torch.tensor([input_sequence], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)  # Forward pass\n",
    "        _, top_k_indices = torch.topk(outputs, k=top_k, dim=1)\n",
    "\n",
    "    top_k_movie_ids = top_k_indices.cpu().numpy()[0]\n",
    "    recommended_movies = [\n",
    "        encoded_movie_id_to_name.get(movie_id, \"Unknown Movie\") for movie_id in top_k_movie_ids\n",
    "    ]\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    with open(\"movie_mappings.pkl\", \"rb\") as f:\n",
    "        mappings = pickle.load(f)\n",
    "        encoded_movie_id_to_name = mappings[\"encoded_movie_id_to_name\"]\n",
    "        encoded_movie_name_to_id = mappings[\"encoded_movie_name_to_id\"]\n",
    "\n",
    "    model = UET4Rec(\n",
    "        num_items=num_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        nhead=nhead,\n",
    "        max_len=max_len,\n",
    "        dropout=0.2,\n",
    "        ff_dim=ff_dim\n",
    "    )\n",
    "    model.load_state_dict(torch.load(\"uet4rec_model_final.pth\", map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Welcome to the Movie Recommendation System!\")\n",
    "    print(\"Type a movie name to get recommendations, or type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Enter a movie name: \").strip()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Thank you for using the Movie Recommendation System. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        recommendations = recommend_movies(\n",
    "            model, user_input, encoded_movie_name_to_id, encoded_movie_id_to_name, top_k=10\n",
    "        )\n",
    "\n",
    "        if isinstance(recommendations, str):  \n",
    "            print(recommendations)\n",
    "        else:\n",
    "            print(f\"\\nRecommendations for '{user_input}':\")\n",
    "            for idx, rec_movie in enumerate(recommendations, 1):\n",
    "                print(f\"{idx}. {rec_movie}\")\n",
    "            print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b490c68-2202-43f1-82b0-63b69c411dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded ID for 'Full Monty, The (1997)': 1378\n"
     ]
    }
   ],
   "source": [
    "def get_encoded_movie_id(movie_name, encoded_movie_name_to_id):\n",
    "    \n",
    "    return encoded_movie_name_to_id.get(movie_name, None)\n",
    "\n",
    "movie_name = \"Full Monty, The (1997)\"  \n",
    "encoded_movie_id = get_encoded_movie_id(movie_name, encoded_movie_name_to_id)\n",
    "\n",
    "if encoded_movie_id:\n",
    "    print(f\"Encoded ID for '{movie_name}': {encoded_movie_id}\")\n",
    "else:\n",
    "    print(f\"Movie '{movie_name}' not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9edb497b-8fd2-4530-93ff-2c03d659c9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "movie_id_to_genres = pd.Series(movies.Genres.values, index=movies.MovieID).to_dict()\n",
    "\n",
    "top_recommended_movies = [1,2695, 1064, 3317, 1593, 1378]  \n",
    "top_recommended_original_ids = [\n",
    "    movie_encoder.inverse_transform([encoded_movie_id])[0]\n",
    "    for encoded_movie_id in top_recommended_movies\n",
    "]\n",
    "\n",
    "top_genres = [movie_id_to_genres[movie_id] for movie_id in top_recommended_original_ids]\n",
    "\n",
    "expanded_genres = []\n",
    "for genre_list in top_genres:\n",
    "    expanded_genres.extend(genre_list.split(\"|\"))\n",
    "\n",
    "genre_counts = Counter(expanded_genres)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(genre_counts.keys(), genre_counts.values(), color=\"skyblue\")\n",
    "plt.title(\"Genre Distribution in Top Recommendations\")\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9623419-8b9a-43bf-bf00-3724186cc83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\npavi\\AppData\\Local\\Temp\\ipykernel_5896\\146851217.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"uet4rec_model_final.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Movie Recommendation System!\n",
      "Type a movie name to get recommendations, or type 'exit' to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a movie name:  Toy Story (1995)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for 'Toy Story (1995)':\n",
      "1. Toy Story 2 (1999)\n",
      "2. Groundhog Day (1993)\n",
      "3. Steel Magnolias (1989)\n",
      "4. There's Something About Mary (1998)\n",
      "5. Full Monty, The (1997)\n",
      "6. Bull Durham (1988)\n",
      "7. American Beauty (1999)\n",
      "8. Scary Movie (2000)\n",
      "9. Young Frankenstein (1974)\n",
      "10. Wizard of Oz, The (1939)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a movie name:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using the Movie Recommendation System. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def recommend_movies(model, movie_name, encoded_movie_name_to_id, encoded_movie_id_to_name, top_k=10):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    if movie_name not in encoded_movie_name_to_id:\n",
    "        return f\"Movie '{movie_name}' not found in the dataset. Please try another movie.\"\n",
    "\n",
    "    input_movie_id = encoded_movie_name_to_id[movie_name]\n",
    "\n",
    "    input_sequence = [0] * (max_len - 1) + [input_movie_id]  # Pad with zeros\n",
    "    input_tensor = torch.tensor([input_sequence], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)  # Forward pass\n",
    "        _, top_k_indices = torch.topk(outputs, k=top_k, dim=1)\n",
    "\n",
    "    top_k_movie_ids = top_k_indices.cpu().numpy()[0]\n",
    "    recommended_movies = [\n",
    "        encoded_movie_id_to_name.get(movie_id, \"Unknown Movie\") for movie_id in top_k_movie_ids\n",
    "    ]\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    with open(\"movie_mappings.pkl\", \"rb\") as f:\n",
    "        mappings = pickle.load(f)\n",
    "        encoded_movie_id_to_name = mappings[\"encoded_movie_id_to_name\"]\n",
    "        encoded_movie_name_to_id = mappings[\"encoded_movie_name_to_id\"]\n",
    "\n",
    "    model = UET4Rec(\n",
    "        num_items=num_items,\n",
    "        embedding_dim=embedding_dim,\n",
    "        nhead=nhead,\n",
    "        max_len=max_len,\n",
    "        dropout=0.2,\n",
    "        ff_dim=ff_dim\n",
    "    )\n",
    "    model.load_state_dict(torch.load(\"uet4rec_model_final.pth\", map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Welcome to the Movie Recommendation System!\")\n",
    "    print(\"Type a movie name to get recommendations, or type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Enter a movie name: \").strip()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Thank you for using the Movie Recommendation System. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        recommendations = recommend_movies(\n",
    "            model, user_input, encoded_movie_name_to_id, encoded_movie_id_to_name, top_k=10\n",
    "        )\n",
    "\n",
    "        if isinstance(recommendations, str):  \n",
    "            print(recommendations)\n",
    "        else:\n",
    "            print(f\"\\nRecommendations for '{user_input}':\")\n",
    "            for idx, rec_movie in enumerate(recommendations, 1):\n",
    "                print(f\"{idx}. {rec_movie}\")\n",
    "            print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5f707d8-c0ed-45e4-81aa-d4f1ad546e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating for k = 5 with batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@5: 0.4739\n",
      "NDCG@5: 0.2795\n",
      "\n",
      "Evaluating for k = 10 with batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10: 0.5774\n",
      "NDCG@10: 0.2624\n",
      "\n",
      "Evaluating for k = 20 with batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@20: 0.6850\n",
      "NDCG@20: 0.2411\n",
      "\n",
      "Metrics Summary:\n",
      "k = 5: HR@5 = 0.4739, NDCG@5 = 0.2795\n",
      "k = 10: HR@10 = 0.5774, NDCG@10 = 0.2624\n",
      "k = 20: HR@20 = 0.6850, NDCG@20 = 0.2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def get_top_k_predictions(model, input_sequence, k=10):\n",
    "    model.eval()  \n",
    "    input_sequence = input_sequence.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_sequence)  \n",
    "\n",
    "    _, top_k_indices = torch.topk(output, k=k, dim=1)  \n",
    "    return top_k_indices.cpu().numpy()\n",
    "\n",
    "def evaluate_model_with_batch_size(model, test_dataset, batch_size, k_values):\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    metrics = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        print(f\"\\nEvaluating for k = {k} with batch size = {batch_size}\")\n",
    "        model.eval()\n",
    "        hits, ndcgs = [], []\n",
    "\n",
    "        for batch_inputs, batch_targets in tqdm(test_loader, desc=f\"Evaluating for k={k}\", leave=False):\n",
    "            batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.cpu().numpy()\n",
    "\n",
    "            top_k_predictions = get_top_k_predictions(model, batch_inputs, k=k)\n",
    "\n",
    "            for i, target in enumerate(batch_targets):\n",
    "                if target in top_k_predictions[i]:\n",
    "                    hits.append(1)  \n",
    "                else:\n",
    "                    hits.append(0)  \n",
    "\n",
    "                true_relevance = np.zeros((1, num_items))\n",
    "                true_relevance[0, target] = 1  \n",
    "                scores = np.zeros((1, num_items))\n",
    "                scores[0, top_k_predictions[i]] = 1  \n",
    "                ndcg = ndcg_score(true_relevance, scores, k=k)\n",
    "                ndcgs.append(ndcg)\n",
    "\n",
    "        hit_rate = np.mean(hits)\n",
    "        avg_ndcg = np.mean(ndcgs)\n",
    "\n",
    "        print(f\"HR@{k}: {hit_rate:.4f}\")\n",
    "        print(f\"NDCG@{k}: {avg_ndcg:.4f}\")\n",
    "        metrics[k] = {\"HR@k\": hit_rate, \"NDCG@k\": avg_ndcg}\n",
    "\n",
    "    return metrics\n",
    "\n",
    "test_batch_size = 64  \n",
    "k_values = [5, 10, 20]\n",
    "\n",
    "metrics = evaluate_model_with_batch_size(model, test_dataset, test_batch_size, k_values)\n",
    "\n",
    "print(\"\\nMetrics Summary:\")\n",
    "for k, values in metrics.items():\n",
    "    print(f\"k = {k}: HR@{k} = {values['HR@k']:.4f}, NDCG@{k} = {values['NDCG@k']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f2293-84d0-475f-82ea-a23781846337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b721df-1e85-4283-8dd8-c48ad00ea51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ffd66-c834-43b2-b99f-514b04573e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9f9873-d69a-4970-ac01-8921255b0cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46073944-55af-4223-ba56-826d834fb53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6ce85-bc16-4657-9e8e-483c5eef34e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fce2f7-3013-4758-8dc0-1c5ecd9edbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d7092b-5660-4d80-971f-17e5c4415c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6558d78-a41a-499f-856a-dbf6be119841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce05f98-7ba4-4564-9d43-6cb616b30b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d296331-7913-470f-bbd3-9ac026681c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2ea63-e9c0-4075-acfb-ce1855d530d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c3b60-a55c-42f1-8187-bbc39420fbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592b4b9-916e-4541-ba1e-1bf1a9a872c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6696ca3-f0bb-4474-812d-514309478c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564e4d6-93c2-4b96-bab4-6d3e2c677ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2a511-c49a-460b-a92f-5a8104a775ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d2c54-d1fd-47f9-b389-d95377fa7126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f2a97-22bb-4391-a471-271e278711da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb301911-6497-42c2-8ab1-b8cea3bce03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe0763e-640d-4c0d-a8ba-a8834a6d1730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90203f3-28a0-4230-a77a-7582301a4283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7dcc1d-b895-4599-a156-bc7d45c2b19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4014fa-e00e-48f4-b46c-4e7f1510f323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65f739-4bd2-4d00-8bc1-31d595656aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e57287e-e5ce-4622-a5b5-187169019c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeaf3ea-ff4b-46b5-bfef-2f34096d33ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafb105-dca1-41d1-9c52-8b4c67ab8558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8eda9-1b45-4d39-9585-065a79ac304d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93123ace-25c3-4dbb-a424-9a8276117277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c8b5a5-333e-4193-8fe9-bfd91be28d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6182999,
     "sourceId": 10037832,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
