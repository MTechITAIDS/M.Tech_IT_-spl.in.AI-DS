{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10233647,"sourceType":"datasetVersion","datasetId":6327686},{"sourceId":10234060,"sourceType":"datasetVersion","datasetId":6327971},{"sourceId":10243533,"sourceType":"datasetVersion","datasetId":6334916},{"sourceId":10243779,"sourceType":"datasetVersion","datasetId":6335099}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\n# instantiate a distribution strategy\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:04:30.310196Z","iopub.execute_input":"2024-12-19T09:04:30.310975Z","iopub.status.idle":"2024-12-19T09:04:54.525333Z","shell.execute_reply.started":"2024-12-19T09:04:30.310932Z","shell.execute_reply":"2024-12-19T09:04:54.524468Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1734599076.831208      13 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD1219 09:04:36.839379540      13 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD1219 09:04:36.839393512      13 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD1219 09:04:36.839396922      13 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD1219 09:04:36.839399492      13 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD1219 09:04:36.839401915      13 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD1219 09:04:36.839404204      13 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD1219 09:04:36.839406517      13 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD1219 09:04:36.839408709      13 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD1219 09:04:36.839410854      13 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD1219 09:04:36.839412999      13 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD1219 09:04:36.839415179      13 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD1219 09:04:36.839417379      13 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD1219 09:04:36.839419587      13 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD1219 09:04:36.839421719      13 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD1219 09:04:36.839423837      13 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD1219 09:04:36.839426022      13 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD1219 09:04:36.839428323      13 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD1219 09:04:36.839430516      13 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD1219 09:04:36.839432719      13 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD1219 09:04:36.839434912      13 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD1219 09:04:36.839437081      13 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD1219 09:04:36.839439295      13 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD1219 09:04:36.839441549      13 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD1219 09:04:36.839443728      13 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD1219 09:04:36.839445852      13 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD1219 09:04:36.839447978      13 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD1219 09:04:36.839450203      13 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD1219 09:04:36.839452408      13 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD1219 09:04:36.839454687      13 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD1219 09:04:36.839457687      13 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD1219 09:04:36.839460056      13 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD1219 09:04:36.839462446      13 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD1219 09:04:36.839464848      13 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD1219 09:04:36.839467336      13 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD1219 09:04:36.839469533      13 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD1219 09:04:36.839471730      13 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD1219 09:04:36.839473883      13 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD1219 09:04:36.839476062      13 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD1219 09:04:36.839478295      13 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD1219 09:04:36.839480496      13 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD1219 09:04:36.839482660      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD1219 09:04:36.839484789      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD1219 09:04:36.839487011      13 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD1219 09:04:36.839489259      13 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD1219 09:04:36.839491494      13 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI1219 09:04:36.839708992      13 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD1219 09:04:36.839723286      13 ev_posix.cc:113]                      Using polling engine: epoll1\nD1219 09:04:36.849914984      13 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1219 09:04:36.849924802      13 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1219 09:04:36.849932011      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1219 09:04:36.849934989      13 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1219 09:04:36.849938167      13 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1219 09:04:36.849941029      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD1219 09:04:36.849971461      13 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1219 09:04:36.849986006      13 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD1219 09:04:36.850000967      13 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1219 09:04:36.850020767      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1219 09:04:36.850027984      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1219 09:04:36.850031174      13 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1219 09:04:36.850034911      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1219 09:04:36.850040646      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1219 09:04:36.850043702      13 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1219 09:04:36.850046769      13 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD1219 09:04:36.850075784      13 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI1219 09:04:36.851659710      13 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI1219 09:04:36.871205951      13 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI1219 09:04:36.874626522     108 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI1219 09:04:36.874688487     108 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1219 09:04:36.880676646      13 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-12-19T09:04:36.88066239+00:00\"}\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734599089.861581      13 service.cc:145] XLA service 0x5845b612adb0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734599089.861633      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1734599089.861637      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1734599089.861640      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1734599089.861643      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1734599089.861646      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1734599089.861649      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1734599089.861651      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1734599089.861654      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install scikit-image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:04:54.526741Z","iopub.execute_input":"2024-12-19T09:04:54.526987Z","iopub.status.idle":"2024-12-19T09:05:01.132277Z","shell.execute_reply.started":"2024-12-19T09:04:54.526957Z","shell.execute_reply":"2024-12-19T09:05:01.131374Z"}},"outputs":[{"name":"stdout","text":"Collecting scikit-image\n  Downloading scikit_image-0.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting tifffile>=2022.8.12\n  Downloading tifffile-2024.12.12-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/site-packages (from scikit-image) (1.14.1)\nRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/site-packages (from scikit-image) (1.26.4)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/site-packages (from scikit-image) (0.4)\nRequirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/site-packages (from scikit-image) (11.0.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/site-packages (from scikit-image) (3.4.2)\nCollecting imageio!=2.35.0,>=2.33\n  Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/site-packages (from scikit-image) (24.2)\nInstalling collected packages: tifffile, imageio, scikit-image\nSuccessfully installed imageio-2.36.1 scikit-image-0.25.0 tifffile-2024.12.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\nfrom skimage import img_as_float\nimport matplotlib.pyplot as plt\nwith tpu_strategy.scope():\n    # Custom simplified NIQE computation\n    def compute_niqe_simplified(image):\n        \"\"\"Simplified approximation of NIQE.\"\"\"\n        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        mean = np.mean(image_gray)\n        std = np.std(image_gray)\n        return mean / (std + 1e-5)  # Simplified NIQE metric\n    \n    # Compute SSIM with proper handling of window size\n    def compute_ssim(img1, img2):\n        min_dim = min(img1.shape[:2])\n        win_size = min(7, min_dim)\n        return ssim(img1, img2, data_range=255, channel_axis=-1, win_size=win_size)\n    \n    # Compute Sharpness (Laplacian variance)\n    def compute_sharpness(image):\n        return cv2.Laplacian(image, cv2.CV_64F).var()\n    \n    # Process and compare two videos\n    def compare_videos(input_video_path_low_quality, input_video_path_enhanced):\n        # Open both videos\n        cap_low_quality = cv2.VideoCapture(input_video_path_low_quality)\n        cap_enhanced = cv2.VideoCapture(input_video_path_enhanced)\n    \n        # Get video properties (assuming both videos have same properties)\n        fps = int(cap_low_quality.get(cv2.CAP_PROP_FPS))\n        width = int(cap_low_quality.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(cap_low_quality.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        total_frames = int(cap_low_quality.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n        # Initialize lists to store metrics\n        psnr_values_low, psnr_values_enhanced = [], []\n        ssim_values_low, ssim_values_enhanced = [], []\n        sharpness_values_low, sharpness_values_enhanced = [], []\n        niqe_values_low, niqe_values_enhanced = [], []\n    \n        frame_idx = 0\n        while cap_low_quality.isOpened() and cap_enhanced.isOpened():\n            ret_low, frame_low = cap_low_quality.read()\n            ret_enhanced, frame_enh = cap_enhanced.read()\n    \n            if not ret_low or not ret_enhanced:\n                break\n    \n            frame_idx += 1\n            print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n    \n            # Ensure the frames are in uint8 format\n            frame_low = (frame_low * 255).astype(np.uint8) if np.max(frame_low) <= 1.0 else frame_low.astype(np.uint8)\n            frame_enh = (frame_enh * 255).astype(np.uint8) if np.max(frame_enh) <= 1.0 else frame_enh.astype(np.uint8)\n    \n            # Compute PSNR, SSIM, Sharpness, and NIQE for both videos\n            psnr_values_low.append(psnr(frame_low, frame_enh, data_range=255))\n            ssim_values_low.append(compute_ssim(frame_low, frame_enh))\n            sharpness_values_low.append(compute_sharpness(frame_low))\n            niqe_values_low.append(compute_niqe_simplified(frame_low))\n    \n            psnr_values_enhanced.append(psnr(frame_enh, frame_low, data_range=255))\n            ssim_values_enhanced.append(compute_ssim(frame_enh, frame_low))\n            sharpness_values_enhanced.append(compute_sharpness(frame_enh))\n            niqe_values_enhanced.append(compute_niqe_simplified(frame_enh))\n    \n        # Release resources\n        cap_low_quality.release()\n        cap_enhanced.release()\n    \n        # Compute average metrics for each video\n        avg_psnr_low = np.mean(psnr_values_low)\n        avg_psnr_enhanced = np.mean(psnr_values_enhanced)\n        avg_ssim_low = np.mean(ssim_values_low)\n        avg_ssim_enhanced = np.mean(ssim_values_enhanced)\n        avg_sharpness_low = np.mean(sharpness_values_low)\n        avg_sharpness_enhanced = np.mean(sharpness_values_enhanced)\n        avg_niqe_low = np.mean(niqe_values_low)\n        avg_niqe_enhanced = np.mean(niqe_values_enhanced)\n    \n        print(\"\\nProcessing completed.\")\n        print(\"Low-Quality Video:\")\n        print(\"Average PSNR:\", avg_psnr_low)\n        print(\"Average SSIM:\", avg_ssim_low)\n        print(\"Average Sharpness (Low-Quality):\", avg_sharpness_low)\n        print(\"Average NIQE (Low-Quality):\", avg_niqe_low)\n    \n        print(\"\\nEnhanced Video:\")\n        print(\"Average PSNR:\", avg_psnr_enhanced)\n        print(\"Average SSIM:\", avg_ssim_enhanced)\n        print(\"Average Sharpness (Enhanced):\", avg_sharpness_enhanced)\n        print(\"Average NIQE (Enhanced):\", avg_niqe_enhanced)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:05:01.133810Z","iopub.execute_input":"2024-12-19T09:05:01.134246Z","iopub.status.idle":"2024-12-19T09:05:03.792289Z","shell.execute_reply.started":"2024-12-19T09:05:01.134211Z","shell.execute_reply":"2024-12-19T09:05:03.791447Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Example Usage\nwith tpu_strategy.scope():\n    input_video_path_low_quality = '/kaggle/input/new2-enhancement/000.mp4'\n    input_video_path_enhanced = '/kaggle/input/new2-enhancement/000_c23.mp4'\n    \n    compare_videos(input_video_path_low_quality, input_video_path_enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:05:03.794257Z","iopub.execute_input":"2024-12-19T09:05:03.794907Z","iopub.status.idle":"2024-12-19T09:07:08.882316Z","shell.execute_reply.started":"2024-12-19T09:05:03.794873Z","shell.execute_reply":"2024-12-19T09:07:08.881368Z"}},"outputs":[{"name":"stdout","text":"Processing frame 396/396\nProcessing completed.\nLow-Quality Video:\nAverage PSNR: 31.886113974939313\nAverage SSIM: 0.9160713974986188\nAverage Sharpness (Low-Quality): 147.71665615292864\nAverage NIQE (Low-Quality): 2.5310765438046423\n\nEnhanced Video:\nAverage PSNR: 31.886113974939313\nAverage SSIM: 0.9160713974986188\nAverage Sharpness (Enhanced): 215.62159953522095\nAverage NIQE (Enhanced): 2.4951498123088456\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"with tpu_strategy.scope():\n    input_video_path_low_quality = '/kaggle/input/new2-enhancement/023.mp4'\n    input_video_path_enhanced = '/kaggle/input/new2-enhancement/023_c23_enhanced_video_new.mp4'\n    \n    compare_videos(input_video_path_low_quality, input_video_path_enhanced)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:07:08.883446Z","iopub.execute_input":"2024-12-19T09:07:08.883839Z","iopub.status.idle":"2024-12-19T09:09:51.515621Z","shell.execute_reply.started":"2024-12-19T09:07:08.883808Z","shell.execute_reply":"2024-12-19T09:09:51.514623Z"}},"outputs":[{"name":"stdout","text":"Processing frame 553/553\nProcessing completed.\nLow-Quality Video:\nAverage PSNR: 25.676724088000217\nAverage SSIM: 0.8314965204540236\nAverage Sharpness (Low-Quality): 141.73033513299367\nAverage NIQE (Low-Quality): 1.488044624354714\n\nEnhanced Video:\nAverage PSNR: 25.676724088000217\nAverage SSIM: 0.8314965204540236\nAverage Sharpness (Enhanced): 668.7435729701459\nAverage NIQE (Enhanced): 1.3608145553626192\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"with tpu_strategy.scope():\n    input_video_path_low_quality = '/kaggle/input/new2-enhancement/459.mp4'\n    input_video_path_enhanced = '/kaggle/input/new2-enhancement/459_enhanced_video_new.mp4'\n    \n    compare_videos(input_video_path_low_quality, input_video_path_enhanced)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:09:51.516898Z","iopub.execute_input":"2024-12-19T09:09:51.517312Z","iopub.status.idle":"2024-12-19T09:27:45.278976Z","shell.execute_reply.started":"2024-12-19T09:09:51.517278Z","shell.execute_reply":"2024-12-19T09:27:45.278010Z"}},"outputs":[{"name":"stdout","text":"Processing frame 526/526\nProcessing completed.\nLow-Quality Video:\nAverage PSNR: 35.10278572379885\nAverage SSIM: 0.9385959945255533\nAverage Sharpness (Low-Quality): 11.436255524528173\nAverage NIQE (Low-Quality): 3.2197726293032884\n\nEnhanced Video:\nAverage PSNR: 35.10278572379885\nAverage SSIM: 0.9385959945255533\nAverage Sharpness (Enhanced): 43.01036867758626\nAverage NIQE (Enhanced): 3.1698124620349546\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"with tpu_strategy.scope():# Example Usage\n    input_video_path_low_quality = '/kaggle/input/new2-enhancement/459.mp4'\n    input_video_path_enhanced = '/kaggle/input/new2-enhancement/459_c23_enhanced_video_new.mp4'\n    \n    compare_videos(input_video_path_low_quality, input_video_path_enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:27:45.280150Z","iopub.execute_input":"2024-12-19T09:27:45.280428Z"}},"outputs":[{"name":"stdout","text":"Processing frame 483/526\r","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Example Usage\nwith tpu_strategy.scope():\n    input_video_path_low_quality = '/kaggle/input/new2-enhancement/818.mp4'\n    input_video_path_enhanced = '/kaggle/input/new2-enhancement/818_enhanced_video_new.mp4'\n    \n    compare_videos(input_video_path_low_quality, input_video_path_enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2024-12-19T09:46:30.757648Z","shell.execute_reply.started":"2024-12-19T09:45:35.976992Z","shell.execute_reply":"2024-12-19T09:46:30.756595Z"}},"outputs":[{"name":"stdout","text":"Processing frame 62/466\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m input_video_path_low_quality \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/new2-enhancement/818.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m input_video_path_enhanced \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/new2-enhancement/818_enhanced_video_new.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mcompare_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path_low_quality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_video_path_enhanced\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[3], line 60\u001b[0m, in \u001b[0;36mcompare_videos\u001b[0;34m(input_video_path_low_quality, input_video_path_enhanced)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Compute PSNR, SSIM, Sharpness, and NIQE for both videos\u001b[39;00m\n\u001b[1;32m     59\u001b[0m psnr_values_low\u001b[38;5;241m.\u001b[39mappend(psnr(frame_low, frame_enh, data_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m))\n\u001b[0;32m---> 60\u001b[0m ssim_values_low\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcompute_ssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_low\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_enh\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     61\u001b[0m sharpness_values_low\u001b[38;5;241m.\u001b[39mappend(compute_sharpness(frame_low))\n\u001b[1;32m     62\u001b[0m niqe_values_low\u001b[38;5;241m.\u001b[39mappend(compute_niqe_simplified(frame_low))\n","Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mcompute_ssim\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m     17\u001b[0m min_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(img1\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     18\u001b[0m win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m7\u001b[39m, min_dim)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_size\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/skimage/metrics/_structural_similarity.py:142\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m _at \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(utils\u001b[38;5;241m.\u001b[39mslice_at_axis, axis\u001b[38;5;241m=\u001b[39mchannel_axis)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nch):\n\u001b[0;32m--> 142\u001b[0m     ch_result \u001b[38;5;241m=\u001b[39m \u001b[43mstructural_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gradient \u001b[38;5;129;01mand\u001b[39;00m full:\n\u001b[1;32m    144\u001b[0m         mssim[ch], G[_at(ch)], S[_at(ch)] \u001b[38;5;241m=\u001b[39m ch_result\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/skimage/metrics/_structural_similarity.py:248\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# compute (weighted) means\u001b[39;00m\n\u001b[1;32m    247\u001b[0m ux \u001b[38;5;241m=\u001b[39m filter_func(im1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_args)\n\u001b[0;32m--> 248\u001b[0m uy \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfilter_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# compute (weighted) variances and covariances\u001b[39;00m\n\u001b[1;32m    251\u001b[0m uxx \u001b[38;5;241m=\u001b[39m filter_func(im1 \u001b[38;5;241m*\u001b[39m im1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_args)\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/scipy/ndimage/_filters.py:1092\u001b[0m, in \u001b[0;36muniform_filter\u001b[0;34m(input, size, output, mode, cval, origin, axes)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1091\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, size, origin, mode \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m-> 1092\u001b[0m         \u001b[43muniform_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/scipy/ndimage/_filters.py:1020\u001b[0m, in \u001b[0;36muniform_filter1d\u001b[0;34m(input, size, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m   1018\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m complex_output:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m                               \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     _nd_image\u001b[38;5;241m.\u001b[39muniform_filter1d(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mreal, size, axis, output\u001b[38;5;241m.\u001b[39mreal, mode,\n\u001b[1;32m   1024\u001b[0m                                np\u001b[38;5;241m.\u001b[39mreal(cval), origin)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"# Example Usage\nwith tpu_strategy.scope():\n    input_video_path_low_quality = '/kaggle/input/new2-enhancement/818.mp4'\n    input_video_path_enhanced = '/kaggle/input/new2-enhancement/818_c23_enhanced_video_new.mp4'\n    \n    compare_videos(input_video_path_low_quality, input_video_path_enhanced)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T09:53:49.249733Z","iopub.execute_input":"2024-12-19T09:53:49.250586Z"}},"outputs":[{"name":"stdout","text":"Processing frame 93/466\r","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"------","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nwith tpu_strategy.scope():\n    # Read input video\n    cap = cv2.VideoCapture('/kaggle/input/c23-dataset/459_c23.mp4')\n    \n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Define codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('/kaggle/working/459_c23_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n        # Denoise and sharpen the frame\n        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n        sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n        sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n    \n        out.write(sharpened)\n    \n    cap.release()\n    out.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T08:13:03.473441Z","iopub.execute_input":"2024-12-19T08:13:03.474350Z","iopub.status.idle":"2024-12-19T08:16:48.408002Z","shell.execute_reply.started":"2024-12-19T08:13:03.474302Z","shell.execute_reply":"2024-12-19T08:16:48.406664Z"}},"outputs":[{"name":"stdout","text":"Processing frame 526/526\r","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import cv2\nimport numpy as np\nwith tpu_strategy.scope():\n    # Read input video\n    cap = cv2.VideoCapture('/kaggle/input/c23-dataset/023_c23.mp4')\n    \n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Define codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('/kaggle/working/023_c23_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n        # Denoise and sharpen the frame\n        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n        sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n        sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n    \n        out.write(sharpened)\n    \n    cap.release()\n    out.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T08:16:53.236475Z","iopub.execute_input":"2024-12-19T08:16:53.236830Z","iopub.status.idle":"2024-12-19T08:20:42.411903Z","shell.execute_reply.started":"2024-12-19T08:16:53.236799Z","shell.execute_reply":"2024-12-19T08:20:42.410963Z"}},"outputs":[{"name":"stdout","text":"Processing frame 553/553\r","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import cv2\nimport numpy as np\nwith tpu_strategy.scope():\n    # Read input video\n    cap = cv2.VideoCapture('/kaggle/input/c23-dataset/818_c23.mp4')\n    \n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Define codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('/kaggle/working/818_c23_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n        # Denoise and sharpen the frame\n        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n        sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n        sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n    \n        out.write(sharpened)\n    \n    cap.release()\n    out.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T08:20:48.700070Z","iopub.execute_input":"2024-12-19T08:20:48.700421Z","iopub.status.idle":"2024-12-19T08:23:47.173061Z","shell.execute_reply.started":"2024-12-19T08:20:48.700392Z","shell.execute_reply":"2024-12-19T08:23:47.172037Z"}},"outputs":[{"name":"stdout","text":"Processing frame 466/466\r","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"-------","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\n# Read input video\ncap = cv2.VideoCapture('/kaggle/input/video-metrics/459.mp4')\n\n# Retrieve the video frame width and height\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter('/kaggle/working/459_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Denoise and sharpen the frame\n    denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n    sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n    sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n\n    out.write(sharpened)\n\ncap.release()\nout.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T06:13:36.863475Z","iopub.execute_input":"2024-12-19T06:13:36.864152Z","iopub.status.idle":"2024-12-19T06:36:46.551766Z","shell.execute_reply.started":"2024-12-19T06:13:36.864117Z","shell.execute_reply":"2024-12-19T06:36:46.551038Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import cv2\n\n# Read input video\ncap = cv2.VideoCapture('/kaggle/input/video-metrics2/023.mp4')\n\n# Define codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nout = cv2.VideoWriter('/kaggle/working/023_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Denoise and sharpen the frame\n    denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n    sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n    sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n\n    out.write(sharpened)\n    cv2.imshow('Frame', sharpened)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\nout.release()\ncv2.destroyAllWindows()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T06:41:03.226090Z","iopub.execute_input":"2024-12-19T06:41:03.226454Z","iopub.status.idle":"2024-12-19T06:44:54.590846Z","shell.execute_reply.started":"2024-12-19T06:41:03.226422Z","shell.execute_reply":"2024-12-19T06:44:54.590140Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import cv2\nimport numpy as np\nwith tpu_strategy.scope():\n    # Read input video\n    cap = cv2.VideoCapture('/kaggle/input/video-metrics/102.mp4')\n    \n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Define codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('/kaggle/working/102_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n        # Denoise and sharpen the frame\n        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n        sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n        sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n    \n        out.write(sharpened)\n    \n    cap.release()\n    out.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T06:58:53.783953Z","iopub.execute_input":"2024-12-19T06:58:53.784312Z","iopub.status.idle":"2024-12-19T07:00:59.095016Z","shell.execute_reply.started":"2024-12-19T06:58:53.784283Z","shell.execute_reply":"2024-12-19T07:00:59.094120Z"}},"outputs":[{"name":"stdout","text":"Processing frame 389/389\r","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import cv2\nimport numpy as np\nwith tpu_strategy.scope():\n    # Read input video\n    cap = cv2.VideoCapture('/kaggle/input/video-metrics/500.mp4')\n    \n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Define codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('/kaggle/working/500_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n        # Denoise and sharpen the frame\n        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n        sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n        sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n    \n        out.write(sharpened)\n    \n    cap.release()\n    out.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T06:53:58.257509Z","iopub.execute_input":"2024-12-19T06:53:58.258102Z","iopub.status.idle":"2024-12-19T06:56:04.762708Z","shell.execute_reply.started":"2024-12-19T06:53:58.258069Z","shell.execute_reply":"2024-12-19T06:56:04.761536Z"}},"outputs":[{"name":"stdout","text":"Processing frame 292/292\r","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import cv2\nimport numpy as np\nwith tpu_strategy.scope():\n    # Read input video\n    cap = cv2.VideoCapture('/kaggle/input/video-metrics/477_487.mp4')\n    \n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Define codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('/kaggle/working/477_487_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n        # Denoise and sharpen the frame\n        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n        sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n        sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n    \n        out.write(sharpened)\n    \n    cap.release()\n    out.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T06:56:14.311516Z","iopub.execute_input":"2024-12-19T06:56:14.311948Z","iopub.status.idle":"2024-12-19T06:58:32.764107Z","shell.execute_reply.started":"2024-12-19T06:56:14.311899Z","shell.execute_reply":"2024-12-19T06:58:32.763240Z"}},"outputs":[{"name":"stdout","text":"Processing frame 365/365\r","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import cv2\nimport numpy as np\nwith tpu_strategy.scope():\n    # Read input video\n    cap = cv2.VideoCapture('/kaggle/input/video-metrics/818.mp4')\n    \n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Define codec and create VideoWriter object\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    out = cv2.VideoWriter('/kaggle/working/818_enhanced_video_new.mp4', fourcc, 30.0, (width, height))\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n        # Denoise and sharpen the frame\n        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)\n        sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n        sharpened = cv2.filter2D(denoised, -1, sharpen_kernel)\n    \n        out.write(sharpened)\n    \n    cap.release()\n    out.release()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T07:01:12.553841Z","iopub.execute_input":"2024-12-19T07:01:12.554213Z","iopub.status.idle":"2024-12-19T07:04:12.416042Z","shell.execute_reply.started":"2024-12-19T07:01:12.554181Z","shell.execute_reply":"2024-12-19T07:04:12.415065Z"}},"outputs":[{"name":"stdout","text":"Processing frame 466/466\r","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"-----------------------------------","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\nfrom skimage import img_as_float\nimport matplotlib.pyplot as plt\n\n# Custom simplified NIQE computation\ndef compute_niqe_simplified(image):\n    \"\"\"Simplified approximation of NIQE.\"\"\"\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    mean = np.mean(image_gray)\n    std = np.std(image_gray)\n    return mean / (std + 1e-5)  # Simplified NIQE metric\n\n# Image Enhancement: Histogram Equalization on each channel\ndef enhance_image(image):\n    if image.max() <= 1.0:\n        image = (image * 255).astype(np.uint8)\n\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    l = l.astype(np.uint8)\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n    l_enhanced = clahe.apply(l)\n    lab_enhanced = cv2.merge((l_enhanced, a, b))\n    enhanced_image = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n    return enhanced_image\n\n# Compute SSIM with proper handling of window size\ndef compute_ssim(img1, img2):\n    min_dim = min(img1.shape[:2])\n    win_size = min(7, min_dim)\n    return ssim(img1, img2, data_range=255, channel_axis=-1, win_size=win_size)\n\n# Process Video\ndef process_video(input_video_path, output_video_path):\n    cap = cv2.VideoCapture(input_video_path)\n\n    # Get video properties\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n    # Video writer for enhanced video\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\n    psnr_values, ssim_values, sharpness_original, sharpness_enhanced = [], [], [], []\n    niqe_original, niqe_enhanced = [], []\n\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n\n        # Enhance frame\n        enhanced_frame = enhance_image(frame)\n\n        # Normalize frames to uint8 if needed\n        frame = (frame * 255).astype(np.uint8) if np.max(frame) <= 1.0 else frame.astype(np.uint8)\n        enhanced_frame = (enhanced_frame * 255).astype(np.uint8) if np.max(enhanced_frame) <= 1.0 else enhanced_frame.astype(np.uint8)\n\n        # Compute metrics\n        psnr_values.append(psnr(frame, enhanced_frame, data_range=255))\n        ssim_values.append(compute_ssim(frame, enhanced_frame))\n        sharpness_original.append(cv2.Laplacian(frame, cv2.CV_64F).var())\n        sharpness_enhanced.append(cv2.Laplacian(enhanced_frame, cv2.CV_64F).var())\n        niqe_original.append(compute_niqe_simplified(frame))\n        niqe_enhanced.append(compute_niqe_simplified(enhanced_frame))\n\n        # Write enhanced frame to output video\n        out.write(enhanced_frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\n    # Compute average metrics\n    avg_psnr = np.mean(psnr_values)\n    avg_ssim = np.mean(ssim_values)\n    avg_sharpness_original = np.mean(sharpness_original)\n    avg_sharpness_enhanced = np.mean(sharpness_enhanced)\n    avg_niqe_original = np.mean(niqe_original)\n    avg_niqe_enhanced = np.mean(niqe_enhanced)\n\n    print(\"\\nProcessing completed.\")\n    print(\"Average PSNR:\", avg_psnr)\n    print(\"Average SSIM:\", avg_ssim)\n    print(\"Average Sharpness (Original):\", avg_sharpness_original)\n    print(\"Average Sharpness (Enhanced):\", avg_sharpness_enhanced)\n    print(\"Average NIQE (Original):\", avg_niqe_original)\n    print(\"Average NIQE (Enhanced):\", avg_niqe_enhanced)\n\n# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/039_058.mp4'\noutput_video_path = '/kaggle/working/039_058_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T08:31:09.206238Z","iopub.execute_input":"2024-12-18T08:31:09.206661Z","iopub.status.idle":"2024-12-18T08:33:09.015022Z","shell.execute_reply.started":"2024-12-18T08:31:09.206631Z","shell.execute_reply":"2024-12-18T08:33:09.014109Z"}},"outputs":[{"name":"stdout","text":"Processing frame 609/609\nProcessing completed.\nAverage PSNR: 19.99177283293613\nAverage SSIM: 0.8530796320636583\nAverage Sharpness (Original): 675.381643535497\nAverage Sharpness (Enhanced): 989.8783054486905\nAverage NIQE (Original): 1.7072791677495633\nAverage NIQE (Enhanced): 1.768468701560128\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\nfrom skimage import img_as_float\nimport matplotlib.pyplot as plt\n\n# Custom simplified NIQE computation\ndef compute_niqe_simplified(image):\n    \"\"\"Simplified approximation of NIQE.\"\"\"\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    mean = np.mean(image_gray)\n    std = np.std(image_gray)\n    return mean / (std + 1e-5)  # Simplified NIQE metric\n\n# Image Enhancement: Histogram Equalization on each channel\ndef enhance_image(image):\n    if image.max() <= 1.0:\n        image = (image * 255).astype(np.uint8)\n\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    l = l.astype(np.uint8)\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n    l_enhanced = clahe.apply(l)\n    lab_enhanced = cv2.merge((l_enhanced, a, b))\n    enhanced_image = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n    return enhanced_image\n\n# Compute SSIM with proper handling of window size\ndef compute_ssim(img1, img2):\n    min_dim = min(img1.shape[:2])\n    win_size = min(7, min_dim)\n    return ssim(img1, img2, data_range=255, channel_axis=-1, win_size=win_size)\n\n# Process Video\ndef process_video(input_video_path, output_video_path):\n    cap = cv2.VideoCapture(input_video_path)\n\n    # Get video properties\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n    # Video writer for enhanced video\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\n    psnr_values, ssim_values, sharpness_original, sharpness_enhanced = [], [], [], []\n    niqe_original, niqe_enhanced = [], []\n\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n\n        # Enhance frame\n        enhanced_frame = enhance_image(frame)\n\n        # Normalize frames to uint8 if needed\n        frame = (frame * 255).astype(np.uint8) if np.max(frame) <= 1.0 else frame.astype(np.uint8)\n        enhanced_frame = (enhanced_frame * 255).astype(np.uint8) if np.max(enhanced_frame) <= 1.0 else enhanced_frame.astype(np.uint8)\n\n        # Compute metrics\n        psnr_values.append(psnr(frame, enhanced_frame, data_range=255))\n        ssim_values.append(compute_ssim(frame, enhanced_frame))\n        sharpness_original.append(cv2.Laplacian(frame, cv2.CV_64F).var())\n        sharpness_enhanced.append(cv2.Laplacian(enhanced_frame, cv2.CV_64F).var())\n        niqe_original.append(compute_niqe_simplified(frame))\n        niqe_enhanced.append(compute_niqe_simplified(enhanced_frame))\n\n        # Write enhanced frame to output video\n        out.write(enhanced_frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\n    # Compute average metrics\n    avg_psnr = np.mean(psnr_values)\n    avg_ssim = np.mean(ssim_values)\n    avg_sharpness_original = np.mean(sharpness_original)\n    avg_sharpness_enhanced = np.mean(sharpness_enhanced)\n    avg_niqe_original = np.mean(niqe_original)\n    avg_niqe_enhanced = np.mean(niqe_enhanced)\n\n    print(\"\\nProcessing completed.\")\n    print(\"Average PSNR:\", avg_psnr)\n    print(\"Average SSIM:\", avg_ssim)\n    print(\"Average Sharpness (Original):\", avg_sharpness_original)\n    print(\"Average Sharpness (Enhanced):\", avg_sharpness_enhanced)\n    print(\"Average NIQE (Original):\", avg_niqe_original)\n    print(\"Average NIQE (Enhanced):\", avg_niqe_enhanced)\n\n# Example Usage\ninput_video_path = '/kaggle/input/video-metrics2/023.mp4'\noutput_video_path = '/kaggle/working/023_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T08:34:26.576903Z","iopub.execute_input":"2024-12-18T08:34:26.577469Z","iopub.status.idle":"2024-12-18T08:36:09.404503Z","shell.execute_reply.started":"2024-12-18T08:34:26.577435Z","shell.execute_reply":"2024-12-18T08:36:09.403629Z"}},"outputs":[{"name":"stdout","text":"Processing frame 553/553\nProcessing completed.\nAverage PSNR: 18.03250120010604\nAverage SSIM: 0.7956313399386197\nAverage Sharpness (Original): 141.73033513299367\nAverage Sharpness (Enhanced): 358.27596305674274\nAverage NIQE (Original): 1.488044624354714\nAverage NIQE (Enhanced): 1.583206514414064\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Example Usage\ninput_video_path = '/kaggle/input/video-metrics2/025_067.mp4'\noutput_video_path = '/kaggle/working/025_067_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T09:05:04.348635Z","iopub.execute_input":"2024-12-18T09:05:04.348990Z","iopub.status.idle":"2024-12-18T09:05:18.726237Z","shell.execute_reply.started":"2024-12-18T09:05:04.348960Z","shell.execute_reply":"2024-12-18T09:05:18.725071Z"}},"outputs":[{"name":"stdout","text":"Processing frame 18/747\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m input_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/video-metrics2/025_067.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/025_067_enhanced_video.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_path\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 70\u001b[0m, in \u001b[0;36mprocess_video\u001b[0;34m(input_video_path, output_video_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n\u001b[1;32m     69\u001b[0m psnr_values\u001b[38;5;241m.\u001b[39mappend(psnr(frame, enhanced_frame, data_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m))\n\u001b[0;32m---> 70\u001b[0m ssim_values\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcompute_ssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menhanced_frame\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     71\u001b[0m sharpness_original\u001b[38;5;241m.\u001b[39mappend(cv2\u001b[38;5;241m.\u001b[39mLaplacian(frame, cv2\u001b[38;5;241m.\u001b[39mCV_64F)\u001b[38;5;241m.\u001b[39mvar())\n\u001b[1;32m     72\u001b[0m sharpness_enhanced\u001b[38;5;241m.\u001b[39mappend(cv2\u001b[38;5;241m.\u001b[39mLaplacian(enhanced_frame, cv2\u001b[38;5;241m.\u001b[39mCV_64F)\u001b[38;5;241m.\u001b[39mvar())\n","Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mcompute_ssim\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m     31\u001b[0m min_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(img1\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     32\u001b[0m win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m7\u001b[39m, min_dim)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_size\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skimage/metrics/_structural_similarity.py:142\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m _at \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(utils\u001b[38;5;241m.\u001b[39mslice_at_axis, axis\u001b[38;5;241m=\u001b[39mchannel_axis)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nch):\n\u001b[0;32m--> 142\u001b[0m     ch_result \u001b[38;5;241m=\u001b[39m \u001b[43mstructural_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gradient \u001b[38;5;129;01mand\u001b[39;00m full:\n\u001b[1;32m    144\u001b[0m         mssim[ch], G[_at(ch)], S[_at(ch)] \u001b[38;5;241m=\u001b[39m ch_result\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skimage/metrics/_structural_similarity.py:275\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[0;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m pad \u001b[38;5;241m=\u001b[39m (win_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# compute (weighted) mean of ssim. Use float64 for accuracy.\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m mssim \u001b[38;5;241m=\u001b[39m \u001b[43mcrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# The following is Eqs. 7-8 of Avanaki 2009.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     grad \u001b[38;5;241m=\u001b[39m filter_func(A1 \u001b[38;5;241m/\u001b[39m D, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfilter_args) \u001b[38;5;241m*\u001b[39m im1\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skimage/util/arraycrop.py:12\u001b[0m, in \u001b[0;36mcrop\u001b[0;34m(ar, crop_width, copy, order)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral\n\u001b[1;32m      9\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrop\u001b[39m(ar, crop_width, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Crop array `ar` by `crop_width` along each dimension.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        view of the input array.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ar, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\nfrom skimage import img_as_float\nimport matplotlib.pyplot as plt\n\n# Custom simplified NIQE computation\ndef compute_niqe_simplified(image):\n    \"\"\"Simplified approximation of NIQE.\"\"\"\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    mean = np.mean(image_gray)\n    std = np.std(image_gray)\n    return mean / (std + 1e-5)  # Simplified NIQE metric\n\n# Image Enhancement: Histogram Equalization on each channel\ndef enhance_image(image):\n    if image.max() <= 1.0:\n        image = (image * 255).astype(np.uint8)\n\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    l = l.astype(np.uint8)\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n    l_enhanced = clahe.apply(l)\n    lab_enhanced = cv2.merge((l_enhanced, a, b))\n    enhanced_image = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n    return enhanced_image\n\n# Compute SSIM with proper handling of window size\ndef compute_ssim(img1, img2):\n    min_dim = min(img1.shape[:2])\n    win_size = min(7, min_dim)\n    return ssim(img1, img2, data_range=255, channel_axis=-1, win_size=win_size)\n\n# Process Video\ndef process_video(input_video_path, output_video_path):\n    cap = cv2.VideoCapture(input_video_path)\n\n    # Get video properties\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n    # Video writer for enhanced video\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\n    psnr_values, ssim_values, sharpness_original, sharpness_enhanced = [], [], [], []\n    niqe_original, niqe_enhanced = [], []\n\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n\n        # Enhance frame\n        enhanced_frame = enhance_image(frame)\n\n        # Normalize frames to uint8 if needed\n        frame = (frame * 255).astype(np.uint8) if np.max(frame) <= 1.0 else frame.astype(np.uint8)\n        enhanced_frame = (enhanced_frame * 255).astype(np.uint8) if np.max(enhanced_frame) <= 1.0 else enhanced_frame.astype(np.uint8)\n\n        # Compute metrics\n        psnr_values.append(psnr(frame, enhanced_frame, data_range=255))\n        ssim_values.append(compute_ssim(frame, enhanced_frame))\n        sharpness_original.append(cv2.Laplacian(frame, cv2.CV_64F).var())\n        sharpness_enhanced.append(cv2.Laplacian(enhanced_frame, cv2.CV_64F).var())\n        niqe_original.append(compute_niqe_simplified(frame))\n        niqe_enhanced.append(compute_niqe_simplified(enhanced_frame))\n\n        # Write enhanced frame to output video\n        out.write(enhanced_frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\n    # Compute average metrics\n    avg_psnr = np.mean(psnr_values)\n    avg_ssim = np.mean(ssim_values)\n    avg_sharpness_original = np.mean(sharpness_original)\n    avg_sharpness_enhanced = np.mean(sharpness_enhanced)\n    avg_niqe_original = np.mean(niqe_original)\n    avg_niqe_enhanced = np.mean(niqe_enhanced)\n\n    print(\"\\nProcessing completed.\")\n    print(\"Average PSNR:\", avg_psnr)\n    print(\"Average SSIM:\", avg_ssim)\n    print(\"Average Sharpness (Original):\", avg_sharpness_original)\n    print(\"Average Sharpness (Enhanced):\", avg_sharpness_enhanced)\n    print(\"Average NIQE (Original):\", avg_niqe_original)\n    print(\"Average NIQE (Enhanced):\", avg_niqe_enhanced)\n\n# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/102.mp4'\noutput_video_path = '/kaggle/working/102_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T08:36:09.428784Z","iopub.execute_input":"2024-12-18T08:36:09.429123Z","iopub.status.idle":"2024-12-18T08:37:33.198372Z","shell.execute_reply.started":"2024-12-18T08:36:09.429089Z","shell.execute_reply":"2024-12-18T08:37:33.197533Z"}},"outputs":[{"name":"stdout","text":"Processing frame 389/389\nProcessing completed.\nAverage PSNR: 19.925091682959803\nAverage SSIM: 0.8028420609908257\nAverage Sharpness (Original): 473.15127148056854\nAverage Sharpness (Enhanced): 646.510046346584\nAverage NIQE (Original): 1.304553232984052\nAverage NIQE (Enhanced): 1.5461315377316767\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\nfrom skimage import img_as_float\nimport matplotlib.pyplot as plt\n\n# Custom simplified NIQE computation\ndef compute_niqe_simplified(image):\n    \"\"\"Simplified approximation of NIQE.\"\"\"\n    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    mean = np.mean(image_gray)\n    std = np.std(image_gray)\n    return mean / (std + 1e-5)  # Simplified NIQE metric\n\n# Image Enhancement: Histogram Equalization on each channel\ndef enhance_image(image):\n    if image.max() <= 1.0:\n        image = (image * 255).astype(np.uint8)\n\n    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    l = l.astype(np.uint8)\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n    l_enhanced = clahe.apply(l)\n    lab_enhanced = cv2.merge((l_enhanced, a, b))\n    enhanced_image = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)\n    return enhanced_image\n\n# Compute SSIM with proper handling of window size\ndef compute_ssim(img1, img2):\n    min_dim = min(img1.shape[:2])\n    win_size = min(7, min_dim)\n    return ssim(img1, img2, data_range=255, channel_axis=-1, win_size=win_size)\n\n# Process Video\ndef process_video(input_video_path, output_video_path):\n    cap = cv2.VideoCapture(input_video_path)\n\n    # Get video properties\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n    # Video writer for enhanced video\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\n    psnr_values, ssim_values, sharpness_original, sharpness_enhanced = [], [], [], []\n    niqe_original, niqe_enhanced = [], []\n\n    frame_idx = 0\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame_idx += 1\n        print(f\"Processing frame {frame_idx}/{total_frames}\", end=\"\\r\")\n\n        # Enhance frame\n        enhanced_frame = enhance_image(frame)\n\n        # Normalize frames to uint8 if needed\n        frame = (frame * 255).astype(np.uint8) if np.max(frame) <= 1.0 else frame.astype(np.uint8)\n        enhanced_frame = (enhanced_frame * 255).astype(np.uint8) if np.max(enhanced_frame) <= 1.0 else enhanced_frame.astype(np.uint8)\n\n        # Compute metrics\n        psnr_values.append(psnr(frame, enhanced_frame, data_range=255))\n        ssim_values.append(compute_ssim(frame, enhanced_frame))\n        sharpness_original.append(cv2.Laplacian(frame, cv2.CV_64F).var())\n        sharpness_enhanced.append(cv2.Laplacian(enhanced_frame, cv2.CV_64F).var())\n        niqe_original.append(compute_niqe_simplified(frame))\n        niqe_enhanced.append(compute_niqe_simplified(enhanced_frame))\n\n        # Write enhanced frame to output video\n        out.write(enhanced_frame)\n\n    # Release resources\n    cap.release()\n    out.release()\n\n    # Compute average metrics\n    avg_psnr = np.mean(psnr_values)\n    avg_ssim = np.mean(ssim_values)\n    avg_sharpness_original = np.mean(sharpness_original)\n    avg_sharpness_enhanced = np.mean(sharpness_enhanced)\n    avg_niqe_original = np.mean(niqe_original)\n    avg_niqe_enhanced = np.mean(niqe_enhanced)\n\n    print(\"\\nProcessing completed.\")\n    print(\"Average PSNR:\", avg_psnr)\n    print(\"Average SSIM:\", avg_ssim)\n    print(\"Average Sharpness (Original):\", avg_sharpness_original)\n    print(\"Average Sharpness (Enhanced):\", avg_sharpness_enhanced)\n    print(\"Average NIQE (Original):\", avg_niqe_original)\n    print(\"Average NIQE (Enhanced):\", avg_niqe_enhanced)\n\n# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/477_487.mp4'\noutput_video_path = '/kaggle/working/477_487_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T08:37:33.200215Z","iopub.execute_input":"2024-12-18T08:37:33.200491Z","iopub.status.idle":"2024-12-18T08:40:21.591939Z","shell.execute_reply.started":"2024-12-18T08:37:33.200464Z","shell.execute_reply":"2024-12-18T08:40:21.591032Z"}},"outputs":[{"name":"stdout","text":"Processing frame 365/365\nProcessing completed.\nAverage PSNR: 15.792193220110514\nAverage SSIM: 0.7342522921895915\nAverage Sharpness (Original): 35.44776589499353\nAverage Sharpness (Enhanced): 145.57336882031032\nAverage NIQE (Original): 1.7449234040782386\nAverage NIQE (Enhanced): 1.8530984364118936\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/459.mp4'\noutput_video_path = '/kaggle/working/459_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T09:24:05.868906Z","iopub.execute_input":"2024-12-18T09:24:05.869672Z"}},"outputs":[{"name":"stdout","text":"Processing frame 383/526\r","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\n# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/500.mp4'\noutput_video_path = '/kaggle/working/500_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T08:54:39.216331Z","iopub.execute_input":"2024-12-18T08:54:39.216688Z","iopub.status.idle":"2024-12-18T09:00:18.019631Z","shell.execute_reply.started":"2024-12-18T08:54:39.216654Z","shell.execute_reply":"2024-12-18T09:00:18.018669Z"}},"outputs":[{"name":"stdout","text":"Processing frame 292/292\nProcessing completed.\nAverage PSNR: 18.155197303813367\nAverage SSIM: 0.8454666387847598\nAverage Sharpness (Original): 127.14719496563379\nAverage Sharpness (Enhanced): 147.3465092644091\nAverage NIQE (Original): 1.1846784586035735\nAverage NIQE (Enhanced): 1.4720926506660685\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/576_155.mp4'\noutput_video_path = '/kaggle/working/576_155_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T09:05:36.793335Z","iopub.execute_input":"2024-12-18T09:05:36.793976Z","iopub.status.idle":"2024-12-18T09:09:46.203254Z","shell.execute_reply.started":"2024-12-18T09:05:36.793939Z","shell.execute_reply":"2024-12-18T09:09:46.202387Z"}},"outputs":[{"name":"stdout","text":"Processing frame 461/461\nProcessing completed.\nAverage PSNR: 20.135472039571024\nAverage SSIM: 0.877855489970095\nAverage Sharpness (Original): 327.79896585445863\nAverage Sharpness (Enhanced): 375.1489025011959\nAverage NIQE (Original): 1.7735371309847419\nAverage NIQE (Enhanced): 1.9937265131858282\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/818.mp4'\noutput_video_path = '/kaggle/working/818_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T09:09:46.205155Z","iopub.execute_input":"2024-12-18T09:09:46.205835Z","iopub.status.idle":"2024-12-18T09:13:53.373214Z","shell.execute_reply.started":"2024-12-18T09:09:46.205763Z","shell.execute_reply":"2024-12-18T09:13:53.372256Z"}},"outputs":[{"name":"stdout","text":"Processing frame 466/466\nProcessing completed.\nAverage PSNR: 15.693198669100951\nAverage SSIM: 0.7577093327601298\nAverage Sharpness (Original): 88.76996410182387\nAverage Sharpness (Enhanced): 151.74040644250192\nAverage NIQE (Original): 1.090023514258419\nAverage NIQE (Enhanced): 1.3845401687325816\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Example Usage\ninput_video_path = '/kaggle/input/video-metrics/996_056.mp4'\noutput_video_path = '/kaggle/working/996_056_enhanced_video.mp4'\nprocess_video(input_video_path, output_video_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T09:13:53.374347Z","iopub.execute_input":"2024-12-18T09:13:53.374630Z","iopub.status.idle":"2024-12-18T09:14:27.149577Z","shell.execute_reply.started":"2024-12-18T09:13:53.374604Z","shell.execute_reply":"2024-12-18T09:14:27.148714Z"}},"outputs":[{"name":"stdout","text":"Processing frame 312/312\nProcessing completed.\nAverage PSNR: 18.823146690480964\nAverage SSIM: 0.7973118162217795\nAverage Sharpness (Original): 250.9983918761574\nAverage Sharpness (Enhanced): 415.20000350403865\nAverage NIQE (Original): 1.346234450409543\nAverage NIQE (Enhanced): 1.5665912615448951\n","output_type":"stream"}],"execution_count":12}]}